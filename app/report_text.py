from __future__ import annotations

from typing import Optional, Dict
from datetime import date
import sqlite3
import pandas as pd
import os

from app.report_basic import (
    build_basic_report,
    build_marketing_report,
    build_quality_report,
)
from etl.data_loader import get_engine
import numpy as np
import re
from ml.inference import load_artifacts, _resolve_preprocessed_feature_groups
import shap
import json


def _fmt_idr(x: Optional[float]) -> str:
    if x is None:
        return "â€”"
    try:
        return f"{int(round(float(x))):,} IDR".replace(",", " ")
    except Exception:
        return str(x)


def _fmt_pct(x: Optional[float], digits: int = 1) -> str:
    if x is None:
        return "â€”"
    return f"{x:.{digits}f}%"


def _fmt_rate(x: Optional[float], digits: int = 2) -> str:
    if x is None:
        return "â€”"
    return f"{x:.{digits}f}"


def _hms_from_minutes(total_minutes: float) -> str:
    m = max(total_minutes, 0)
    hours = int(m // 60)
    minutes = int(m % 60)
    seconds = int(round((m - int(m)) * 60))
    return f"{hours}:{minutes:02d}:{seconds:02d}"


def _sec_to_minutes(avg_seconds: float) -> float:
    return float(avg_seconds) / 60.0


def _section1_exec(basic: Dict) -> str:
    es = basic["executive_summary"]
    grab = es["by_platform"]["grab"]
    gojek = es["by_platform"]["gojek"]

    total_rev = _fmt_idr(es["revenue_total"])
    grab_rev = _fmt_idr(grab.get("sales"))
    gojek_rev = _fmt_idr(gojek.get("sales"))

    total_orders = es.get("orders_total") or 0
    # Optional enriched fields
    fake = es.get("fake_orders", {})
    canc = es.get("cancellations", {})
    lost = es.get("lost_orders", {})
    succ = es.get("successful_orders", {})
    aov = es.get("aov", {})

    lines = []
    lines.append("ðŸ“Š 1. Ð˜Ð¡ÐŸÐžÐ›ÐÐ˜Ð¢Ð•Ð›Ð¬ÐÐžÐ• Ð Ð•Ð—Ð®ÐœÐ•")
    lines.append("â€”" * 72)
    lines.append(f"ðŸ’° ÐžÐ±Ñ‰Ð°Ñ Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°: {total_rev} (GRAB: {grab_rev} + GOJEK: {gojek_rev})")
    lines.append(f"ðŸ“¦ ÐžÐ±Ñ‰Ð¸Ðµ Ð·Ð°ÐºÐ°Ð·Ñ‹: {total_orders}")
    lines.append(f"   â”œâ”€â”€ ðŸ“± GRAB: {int(grab.get('orders') or 0)} (ÑƒÑÐ¿ÐµÑˆÐ½Ð¾: {succ.get('grab','â€”')}, Ð¾Ñ‚Ð¼ÐµÐ½Ñ‹: {canc.get('grab','â€”')}, Ð¿Ð¾Ñ‚ÐµÑ€Ð¸: {lost.get('grab','â€”')}, fake: {fake.get('grab','â€”')})")
    lines.append(f"   â””â”€â”€ ðŸ›µ GOJEK: {int(gojek.get('orders') or 0)} (ÑƒÑÐ¿ÐµÑˆÐ½Ð¾: {succ.get('gojek','â€”')}, Ð¾Ñ‚Ð¼ÐµÐ½Ñ‹: {canc.get('gojek','â€”')}, Ð¿Ð¾Ñ‚ÐµÑ€Ð¸: {lost.get('gojek','â€”')}, fake: {fake.get('gojek','â€”')})")
    # AOVs
    if aov:
        lines.append(f"ðŸ’µ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ‡ÐµÐº (ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ðµ): Ð¾Ð±Ñ‰Ð¸Ð¹ { _fmt_idr(aov.get('total')) }; GRAB { _fmt_idr(aov.get('grab')) }; GOJEK { _fmt_idr(aov.get('gojek')) }")
    # Daily revenue
    drw = es.get('daily_revenue_workdays_avg')
    if drw is not None:
        lines.append(f"ðŸ“Š Ð”Ð½ÐµÐ²Ð½Ð°Ñ Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°: {_fmt_idr(drw)} (ÑÑ€ÐµÐ´Ð½ÑÑ Ð¿Ð¾ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ð¼ Ð´Ð½ÑÐ¼)")
    # Rating
    rat = es.get('rating_avg_total')
    if rat:
        lines.append(f"â­ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³: {_fmt_rate(float(rat), 2)}/5.0")
    # Clients
    cli = es.get('clients', {})
    if cli:
        tot = cli.get('total_unique')
        lines.append(f"ðŸ‘¥ ÐžÐ±ÑÐ»ÑƒÐ¶ÐµÐ½Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²: {tot if tot is not None else 'â€”'}")
        g = cli.get('grab', {})
        j = cli.get('gojek', {})
        lines.append(f"   â”œâ”€â”€ ðŸ“± GRAB: {g.get('total','â€”')} (Ð½Ð¾Ð²Ñ‹Ðµ: {g.get('new','â€”')}, Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ðµ: {g.get('repeated','â€”')}, Ñ€ÐµÐ°ÐºÑ‚Ð¸Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ: {g.get('reactivated','â€”')})")
        lines.append(f"   â””â”€â”€ ðŸ›µ GOJEK: {j.get('new','â€”') + j.get('active','â€”') + j.get('returned','â€”') if all(isinstance(j.get(k), int) for k in ['new','active','returned']) else 'â€”'} (Ð½Ð¾Ð²Ñ‹Ðµ: {j.get('new','â€”')}, Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ: {j.get('active','â€”')}, Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð¸Ð²ÑˆÐ¸ÐµÑÑ: {j.get('returned','â€”')})")
        if tot is not None:
            lines.append(f"   ðŸ’¡ ÐžÐ±Ñ‰Ð¸Ð¹ Ð¾Ñ…Ð²Ð°Ñ‚: {tot} ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²")
    # Marketing budget
    mb = es.get('marketing_budget', {})
    if mb:
        total_b = mb.get('total') or 0.0
        lines.append(f"ðŸ’¸ ÐœÐ°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ð¹ Ð±ÑŽÐ´Ð¶ÐµÑ‚: {_fmt_idr(total_b)} ({_fmt_pct(mb.get('share_of_revenue_pct'))} Ð¾Ñ‚ Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ¸)")
        lines.append("ðŸ“Š Ð”ÐµÑ‚Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ñ‹Ñ… Ð·Ð°Ñ‚Ñ€Ð°Ñ‚:")
        lines.append("   â”Œâ”€ ðŸ“± GRAB:")
        lines.append(f"   â”‚  ðŸ’° Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {_fmt_idr(mb.get('grab'))}")
        # Additional ratios require per-platform revenue; already printed above implicitly; keep budget split concise
        lines.append("   â””â”€ ðŸ›µ GOJEK:")
        lines.append(f"      ðŸ’° Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {_fmt_idr(mb.get('gojek'))}")
    # ROAS summary
    ro = es.get('roas', {})
    if ro:
        lines.append("")
        lines.append("ðŸŽ¯ ROAS ÐÐÐÐ›Ð˜Ð—:")
        lines.append(f"â”œâ”€â”€ ðŸ“± GRAB: {_fmt_rate(ro.get('grab'))}x")
        lines.append(f"â”œâ”€â”€ ðŸ›µ GOJEK: {_fmt_rate(ro.get('gojek'))}x")
        lines.append(f"â””â”€â”€ ðŸŽ¯ ÐžÐ‘Ð©Ð˜Ð™: {_fmt_rate(ro.get('total'))}x")
    return "\n".join(lines)


def _dataset_version_banner() -> str:
    try:
        metrics_path = "/workspace/ml/artifacts/metrics.json"
        if not os.path.exists(metrics_path):
            return ""
        with open(metrics_path, "r", encoding="utf-8") as f:
            m = json.load(f)
        h = str(m.get("dataset_hash",""))
        rows = m.get("dataset_rows")
        ts = m.get("run_at_utc")
        champ = m.get("champion")
        short = h[:10] if h else ""
        return f"Ð’ÐµÑ€ÑÐ¸Ñ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°: {short} Â· ÑÑ‚Ñ€Ð¾Ðº: {rows} Â· Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð°Ð»ÑÑ: {ts} Â· Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {champ}"
    except Exception:
        return ""


def _section2_trends(basic: Dict) -> str:
    st = basic["sales_trends"]
    monthly = st.get("monthly", {})
    lines = []
    lines.append("ðŸ“ˆ 2. ÐÐÐÐ›Ð˜Ð— ÐŸÐ ÐžÐ”ÐÐ– Ð˜ Ð¢Ð Ð•ÐÐ”ÐžÐ’")
    lines.append("â€”" * 72)
    lines.append("ðŸ“Š Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð¿Ð¾ Ð¼ÐµÑÑÑ†Ð°Ð¼:")
    for ym in sorted(monthly.keys()):
        m = monthly[ym]
        lines.append(
            f"  {ym}: {_fmt_idr(m['total_sales'])} ({m['days']} Ð´Ð½ÐµÐ¹, {_fmt_idr(m['avg_per_day'])}/Ð´ÐµÐ½ÑŒ)"
        )
    w = st.get("weekend_vs_weekday", {})
    lines.append("")
    lines.append("ðŸ—“ï¸ Ð’Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ vs Ð‘ÑƒÐ´Ð½Ð¸:")
    lines.append(f"  ðŸ“… Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸ Ð² Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ: {_fmt_idr(w.get('weekend_avg'))}")
    lines.append(f"  ðŸ“… Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸ Ð² Ð±ÑƒÐ´Ð½Ð¸: {_fmt_idr(w.get('weekday_avg'))}")
    lines.append(f"  ðŸ“Š Ð­Ñ„Ñ„ÐµÐºÑ‚ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ñ…: {_fmt_pct(w.get('effect_pct'))}")

    best = st.get("best_day")
    worst = st.get("worst_day")
    if best:
        gp = best.get("by_platform", {})
        lines.append("ðŸ“Š ÐÐÐÐ›Ð˜Ð— Ð ÐÐ‘ÐžÐ§Ð˜Ð¥ Ð”ÐÐ•Ð™:")
        lines.append(
            f"ðŸ† Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ð´ÐµÐ½ÑŒ: {best['date']} - {_fmt_idr(best['total_sales'])}"
        )
        lines.append(
            f"   ðŸ’° GRAB: {_fmt_idr(gp.get('grab',{}).get('sales'))} ({int(gp.get('grab',{}).get('orders') or 0)} Ð·Ð°ÐºÐ°Ð·Ð¾Ð²) | "
            f"GOJEK: {_fmt_idr(gp.get('gojek',{}).get('sales'))} ({int(gp.get('gojek',{}).get('orders') or 0)} Ð·Ð°ÐºÐ°Ð·Ð¾Ð²)"
        )
    if worst:
        gp = worst.get("by_platform", {})
        lines.append(
            f"ðŸ“‰ Ð¥ÑƒÐ´ÑˆÐ¸Ð¹ Ð´ÐµÐ½ÑŒ: {worst['date']} - {_fmt_idr(worst['total_sales'])}"
        )
        lines.append(
            f"   ðŸ’° GRAB: {_fmt_idr(gp.get('grab',{}).get('sales'))} | GOJEK: {_fmt_idr(gp.get('gojek',{}).get('sales'))}"
        )
    return "\n".join(lines)


def _section4_marketing(mkt: Dict) -> str:
    f = mkt.get("funnel_grab", {})
    rm = mkt.get("roas_by_month", {})
    lines = []
    lines.append("ðŸ“ˆ 4. ÐœÐÐ ÐšÐ•Ð¢Ð˜ÐÐ“ÐžÐ’ÐÐ¯ Ð­Ð¤Ð¤Ð•ÐšÐ¢Ð˜Ð’ÐÐžÐ¡Ð¢Ð¬ Ð˜ Ð’ÐžÐ ÐžÐÐšÐ")
    lines.append("â€”" * 72)
    lines.append("ðŸ“Š ÐœÐ°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³Ð¾Ð²Ð°Ñ Ð²Ð¾Ñ€Ð¾Ð½ÐºÐ° (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ GRAB):")
    lines.append(f"  ðŸ‘ï¸ ÐŸÐ¾ÐºÐ°Ð·Ñ‹ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹: {int(f.get('impressions') or 0)}")
    lines.append(
        f"  ðŸ”— ÐŸÐ¾ÑÐµÑ‰ÐµÐ½Ð¸Ñ Ð¼ÐµÐ½ÑŽ: {int(f.get('menu_visits') or 0)} (CTR: {_fmt_pct((f.get('ctr') or 0)*100)})"
    )
    lines.append(
        f"  ðŸ›’ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð² ÐºÐ¾Ñ€Ð·Ð¸Ð½Ñƒ: {int(f.get('add_to_cart') or 0)} (ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ñ: {_fmt_pct((f.get('conv_click_to_order') or 0)*100)} Ð¾Ñ‚ ÐºÐ»Ð¸ÐºÐ¾Ð²)"
    )
    lines.append(
        f"  ðŸ“¦ Ð—Ð°ÐºÐ°Ð·Ñ‹ Ð¾Ñ‚ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹: {int(f.get('ads_orders') or 0)} (ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ñ: {_fmt_pct((f.get('conv_cart_to_order') or 0)*100)} Ð¾Ñ‚ ÐºÐ¾Ñ€Ð·Ð¸Ð½Ñ‹)"
    )
    lines.append("")
    lines.append("  ðŸ“Š ÐšÐ›Ð®Ð§Ð•Ð’Ð«Ð• ÐšÐžÐÐ’Ð•Ð Ð¡Ð˜Ð˜:")
    lines.append(f"  â€¢ ðŸŽ¯ ÐŸÐ¾ÐºÐ°Ð· â†’ Ð—Ð°ÐºÐ°Ð·: {_fmt_pct((f.get('show_to_order') or 0)*100)}")
    lines.append(f"  â€¢ ðŸ”— ÐšÐ»Ð¸Ðº â†’ Ð—Ð°ÐºÐ°Ð·: {_fmt_pct((f.get('conv_click_to_order') or 0)*100)}")
    lines.append(f"  â€¢ ðŸ›’ ÐšÐ¾Ñ€Ð·Ð¸Ð½Ð° â†’ Ð—Ð°ÐºÐ°Ð·: {_fmt_pct((f.get('conv_cart_to_order') or 0)*100)}")
    lines.append("")
    bouncers = int(max((f.get('menu_visits') or 0) - (f.get('add_to_cart') or 0), 0))
    aband = int(max((f.get('add_to_cart') or 0) - (f.get('ads_orders') or 0), 0))
    lines.append("  ðŸ“‰ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— Ð’ÐžÐ ÐžÐÐšÐ˜:")
    lines.append(
        f"  â€¢ ðŸ’” Ð”Ð¾Ð»Ñ ÑƒÑˆÐµÐ´ÑˆÐ¸Ñ… Ð±ÐµÐ· Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸: {_fmt_pct((f.get('bounce_rate') or 0)*100)} ({bouncers} ÑƒÑˆÐ»Ð¸ Ð±ÐµÐ· Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸)"
    )
    lines.append(
        f"  â€¢ ðŸ›’ Ð”Ð¾Ð»Ñ Ð½ÐµÐ¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ¾Ñ€Ð·Ð¸Ð½: {_fmt_pct((f.get('abandoned_carts_rate') or 0)*100)} ({aband} Ð´Ð¾Ð±Ð°Ð²Ð¸Ð»Ð¸, Ð½Ð¾ Ð½Ðµ ÐºÑƒÐ¿Ð¸Ð»Ð¸)"
    )
    lines.append("")
    lines.append("  ðŸ’° ÐŸÐžÐ¢Ð•ÐÐ¦Ð˜ÐÐ› ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð˜ Ð’ÐžÐ ÐžÐÐšÐ˜:")
    up = f.get("uplift_estimations", {})
    lines.append(
        f"  â€¢ ðŸ“ˆ Ð¡Ð½Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð»Ð¸ ÑƒÑˆÐµÐ´ÑˆÐ¸Ñ… Ð½Ð° 10%: {_fmt_idr(up.get('reduce_bounce_10_pct_revenue'))}"
    )
    lines.append(
        f"  â€¢ ðŸ›’ Ð£ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð½ÐµÐ¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ¾Ñ€Ð·Ð¸Ð½: {_fmt_idr(up.get('eliminate_abandoned_revenue'))}"
    )
    lines.append(
        f"  â€¢ ðŸŽ¯ ÐžÐ±Ñ‰Ð¸Ð¹ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»: {_fmt_idr(up.get('total_uplift'))}"
    )
    lines.append("")
    lines.append("ðŸ’¸ Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ (GRAB):")
    lines.append(
        f"  ðŸ’° CPC: {_fmt_idr(f.get('cpc'))} (Ñ€Ð°ÑÑ‡Ñ‘Ñ‚: Ð±ÑŽÐ´Ð¶ÐµÑ‚ Ã· Ð¿Ð¾ÑÐµÑ‰ÐµÐ½Ð¸Ñ Ð¼ÐµÐ½ÑŽ)" 
    )
    lines.append(
        f"  ðŸ’° CPA: {_fmt_idr(f.get('cpa'))} (Ñ€Ð°ÑÑ‡Ñ‘Ñ‚: Ð±ÑŽÐ´Ð¶ÐµÑ‚ Ã· Ð·Ð°ÐºÐ°Ð·Ñ‹ Ð¾Ñ‚ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹)"
    )
    return "\n".join(lines)


def _section5_finance(fin: Dict) -> str:
    lines = []
    lines.append("5. ðŸ’³ Ð¤Ð˜ÐÐÐÐ¡ÐžÐ’Ð«Ð• ÐŸÐžÐšÐÐ—ÐÐ¢Ð•Ð›Ð˜")
    lines.append("â€”" * 72)
    payouts = fin.get("payouts", {})
    total_payouts = payouts.get("total") or 0.0
    grab_p = payouts.get("grab") or 0.0
    gojek_p = payouts.get("gojek") or 0.0
    grab_pct = (grab_p / total_payouts * 100.0) if total_payouts else None
    gojek_pct = (gojek_p / total_payouts * 100.0) if total_payouts else None
    lines.append("ðŸ’° Ð’Ñ‹Ð¿Ð»Ð°Ñ‚Ñ‹:")
    lines.append(f"   â”œâ”€â”€ ðŸ“± GRAB: {_fmt_idr(grab_p)} ({_fmt_pct(grab_pct)})")
    lines.append(f"   â”œâ”€â”€ ðŸ›µ GOJEK: {_fmt_idr(gojek_p)} ({_fmt_pct(gojek_pct)})")
    lines.append(f"   â””â”€â”€ ðŸ’Ž ÐžÐ±Ñ‰Ð¸Ðµ Ð²Ñ‹Ð¿Ð»Ð°Ñ‚Ñ‹: {_fmt_idr(total_payouts)}")

    ad_sales = fin.get("ad_sales")
    ad_share = (fin.get("ad_sales_share") or 0.0) * 100.0
    lines.append("ðŸ“Š Ð ÐµÐºÐ»Ð°Ð¼Ð½Ð°Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ:")
    lines.append(f"   â”œâ”€â”€ ðŸ’° ÐžÐ±Ñ‰Ð¸Ðµ Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸: {_fmt_idr(ad_sales)}")
    lines.append(f"   â”œâ”€â”€ ðŸ“ˆ Ð”Ð¾Ð»Ñ Ð¾Ñ‚ Ð¾Ð±Ñ‰Ð¸Ñ… Ð¿Ñ€Ð¾Ð´Ð°Ð¶: {_fmt_pct(ad_share)}")
    lines.append(
        f"   â”œâ”€â”€ ðŸŽ¯ GRAB ROAS: {_fmt_rate(fin.get('roas',{}).get('grab'))}x"
    )
    lines.append(
        f"   â””â”€â”€ ðŸŽ¯ GOJEK ROAS: {_fmt_rate(fin.get('roas',{}).get('gojek'))}x"
    )

    tr = fin.get("take_rate", {})
    net_roas = fin.get("net_roas", {})
    lines.append("")
    lines.append("Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾:")
    lines.append(
        f"   â€¢ Take rate (Ð´Ð¾Ð»Ñ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ð¹ Ð¸ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ð¹): GRAB { _fmt_pct((tr.get('grab') or 0.0)*100) }, GOJEK { _fmt_pct((tr.get('gojek') or 0.0)*100) }"
    )
    lines.append(
        f"   â€¢ Ð§Ð¸ÑÑ‚Ñ‹Ð¹ ROAS: GRAB {_fmt_rate(net_roas.get('grab'))}x; GOJEK {_fmt_rate(net_roas.get('gojek'))}x"
    )
    contrib = fin.get("contribution_per_ad_order_grab")
    if contrib is not None:
        lines.append(
            f"   â€¢ Ð®Ð½Ð¸Ñ‚â€‘ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸ÐºÐ° Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð¾Ð³Ð¾ Ð·Ð°ÐºÐ°Ð·Ð° (GRAB): {_fmt_idr(contrib)}"
        )
    return "\n".join(lines)


def _parse_time_to_minutes(val: str) -> Optional[float]:
    if val is None:
        return None
    s = str(val)
    parts = s.split(":")
    try:
        if len(parts) == 3:
            h, m, sec = parts
            return int(h) * 60 + int(m) + int(sec) / 60.0
        if len(parts) == 2:
            h, m = parts
            return int(h) * 60 + int(m)
        # fallback numeric
        return float(s)
    except Exception:
        return None


def _section6_operations(period: str, restaurant_id: int) -> str:
    eng = get_engine()
    start_str, end_str = period.split("_")
    start = pd.to_datetime(start_str)
    end = pd.to_datetime(end_str)

    # GRAB driver_waiting_time JSON average (seconds -> minutes if needed)
    qg = (
        "SELECT driver_waiting_time FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ? "
        "AND driver_waiting_time IS NOT NULL"
    )
    g = pd.read_sql_query(qg, eng, params=(restaurant_id, start_str, end_str))
    grab_wait_vals = []
    for v in g['driver_waiting_time'].dropna().tolist():
        try:
            if isinstance(v, str) and v.strip().startswith('{'):
                d = pd.read_json(pd.io.common.StringIO(v), typ='series') if False else None
                # Fallback manual parse
                import json as _json
                d = _json.loads(v)
                for k in ('avg','average','minutes','mean'):
                    if k in d:
                        val = float(d[k])
                        # heuristic: if seconds, convert to minutes
                        grab_wait_vals.append(val/60.0 if val > 60 else val)
                        break
            elif isinstance(v, (int, float)):
                val = float(v)
                grab_wait_vals.append(val/60.0 if val > 60 else val)
        except Exception:
            pass
    grab_wait_avg = sum(grab_wait_vals)/len(grab_wait_vals) if grab_wait_vals else None

    # GOJEK times
    qj = (
        "SELECT accepting_time, preparation_time, delivery_time, driver_waiting, close_time, stat_date "
        "FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?"
    )
    j = pd.read_sql_query(qj, eng, params=(restaurant_id, start_str, end_str))
    acc = pd.Series([_parse_time_to_minutes(x) for x in j['accepting_time'] if pd.notna(x)])
    prep = pd.Series([_parse_time_to_minutes(x) for x in j['preparation_time'] if pd.notna(x)])
    delv = pd.Series([_parse_time_to_minutes(x) for x in j['delivery_time'] if pd.notna(x)])
    drvw = pd.to_numeric(j['driver_waiting'], errors='coerce').dropna()

    # cancellations
    Cg = pd.read_sql_query(
        "SELECT SUM(cancelled_orders) c FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
        eng, params=(restaurant_id, start_str, end_str)
    ).iloc[0]['c'] or 0
    Cj_row = pd.read_sql_query(
        "SELECT SUM(cancelled_orders) c, SUM(lost_orders) l FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
        eng, params=(restaurant_id, start_str, end_str)
    ).iloc[0]
    Cj = Cj_row['c'] or 0; Lj = Cj_row['l'] or 0
    orders_total = (
        (pd.read_sql_query("SELECT SUM(orders) o FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?", eng, params=(restaurant_id, start_str, end_str)).iloc[0]['o'] or 0)
        + (pd.read_sql_query("SELECT SUM(orders) o FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?", eng, params=(restaurant_id, start_str, end_str)).iloc[0]['o'] or 0)
    )
    cancel_rate = ((Cg + Cj) / orders_total * 100.0) if orders_total else None

    # outages events > 1 hour
    events = []
    # GRAB offline_rate in minutes
    og = pd.read_sql_query(
        "SELECT stat_date, offline_rate FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ? AND offline_rate IS NOT NULL",
        eng, params=(restaurant_id, start_str, end_str)
    )
    for _, row in og.iterrows():
        mins = float(row['offline_rate'] or 0)
        if mins >= 60.0:
            events.append((pd.to_datetime(row['stat_date']).date(), 'GRAB', mins/60.0))
    # GOJEK close_time HH:MM:SS
    oj = pd.read_sql_query(
        "SELECT stat_date, close_time FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
        eng, params=(restaurant_id, start_str, end_str)
    )
    for _, row in oj.iterrows():
        ct = str(row['close_time']) if pd.notna(row['close_time']) else ''
        parts = ct.split(':')
        seconds = None
        try:
            if len(parts) == 3:
                h, m, s = parts
                seconds = int(h)*3600 + int(m)*60 + int(s)
        except Exception:
            seconds = None
        if seconds and seconds >= 3600:
            events.append((pd.to_datetime(row['stat_date']).date(), 'GOJEK', seconds/3600.0))

    # Potential losses
    # average hourly revenue by platform
    # platform sales
    sg = pd.read_sql_query(
        "SELECT SUM(sales) s FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
        eng, params=(restaurant_id, start_str, end_str)
    ).iloc[0]['s'] or 0.0
    sj = pd.read_sql_query(
        "SELECT SUM(sales) s FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
        eng, params=(restaurant_id, start_str, end_str)
    ).iloc[0]['s'] or 0.0
    num_days = (end - start).days + 1
    hr_g = (sg / (num_days*24.0)) if num_days>0 else 0.0
    hr_j = (sj / (num_days*24.0)) if num_days>0 else 0.0

    total_loss_g = sum((hrs*hr_g) for (d,plat,hrs) in events if plat=='GRAB')
    total_loss_j = sum((hrs*hr_j) for (d,plat,hrs) in events if plat=='GOJEK')

    lines = []
    lines.append("6. â° ÐžÐŸÐ•Ð ÐÐ¦Ð˜ÐžÐÐÐ«Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜")
    lines.append("â€”" * 72)
    lines.append("ðŸŸ¢ GRAB:")
    lines.append(f"â””â”€â”€ â° Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÐµÐ¹: {_fmt_rate(grab_wait_avg,1)} Ð¼Ð¸Ð½")
    lines.append("")
    lines.append("ðŸŸ  GOJEK:")
    lines.append(f"â”œâ”€â”€ â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ: {_fmt_rate(prep.mean() if not prep.empty else None,1)} Ð¼Ð¸Ð½")
    lines.append(f"â”œâ”€â”€ ðŸš— Ð’Ñ€ÐµÐ¼Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸: {_fmt_rate(delv.mean() if not delv.empty else None,1)} Ð¼Ð¸Ð½  ")
    lines.append(f"â””â”€â”€ â° Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÐµÐ¹: {_fmt_rate(drvw.mean() if not drvw.empty else None,1)} Ð¼Ð¸Ð½")
    lines.append("")
    lines.append("âš ï¸ ÐžÐŸÐ•Ð ÐÐ¦Ð˜ÐžÐÐÐÐ¯ Ð­Ð¤Ð¤Ð•ÐšÐ¢Ð˜Ð’ÐÐžÐ¡Ð¢Ð¬")
    lines.append("â€”" * 72)
    lines.append("ðŸš« ÐžÑ‚Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð°ÐºÐ°Ð·Ñ‹:")
    lines.append(f"   â”œâ”€â”€ ðŸ“± GRAB: {int(Cg)} Ð·Ð°ÐºÐ°Ð·Ð°")
    lines.append(f"   â””â”€â”€ ðŸ›µ GOJEK: {int(Cj)} Ð·Ð°ÐºÐ°Ð·Ð°")
    lines.append(f"   ðŸ’¡ Ð’ÑÐµÐ³Ð¾ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ñ…: {int(Cg+Cj)} Ð·Ð°ÐºÐ°Ð·Ð¾Ð² ({_fmt_pct(cancel_rate)})")
    lines.append("")
    if events:
        total_loss = total_loss_g + total_loss_j
        total_sales = sg + sj
        loss_pct = (total_loss/total_sales*100.0) if total_sales else None
        lines.append("ðŸ”§ ÐžÐŸÐ•Ð ÐÐ¦Ð˜ÐžÐÐÐ«Ð• Ð¡Ð‘ÐžÐ˜ ÐŸÐ›ÐÐ¢Ð¤ÐžÐ Ðœ:")
        # aggregate durations per platform
        dur_g = sum(hrs for (_,plat,hrs) in events if plat=='GRAB')
        dur_j = sum(hrs for (_,plat,hrs) in events if plat=='GOJEK')
        from datetime import timedelta
        def hms_from_hours(h):
            h_int = int(h)
            m = int((h - h_int)*60)
            s = int(round(((h - h_int)*60 - m)*60))
            return f"{h_int}:{m:02d}:{s:02d}"
        lines.append(f"â”œâ”€â”€ ðŸ“± GRAB: {len([1 for _,p,_ in events if p=='GRAB'])} ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð´Ð½Ñ ({hms_from_hours(dur_g)} Ð¾Ð±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ)")
        lines.append(f"â”œâ”€â”€ ðŸ›µ GOJEK: {len([1 for _,p,_ in events if p=='GOJEK'])} ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð´Ð½Ñ ({hms_from_hours(dur_j)} Ð¾Ð±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ)")
        lines.append(f"â””â”€â”€ ðŸ’¸ ÐŸÐ¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ñ‚ÐµÑ€Ð¸: {_fmt_idr(total_loss)} ({_fmt_pct(loss_pct)})")
        if events:
            lines.append("")
            lines.append("ðŸš¨ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð¡Ð‘ÐžÐ˜ (>1 Ñ‡Ð°ÑÐ°):")
            # sort by date
            for d, plat, hrs in sorted(events, key=lambda x: x[0]):
                loss = hrs*(hr_g if plat=='GRAB' else hr_j)
                lines.append(f"   â€¢ {d}: {plat} offline {hms_from_hours(hrs)} (Ð¿Ð¾Ñ‚ÐµÑ€Ð¸: ~{_fmt_idr(loss)})")
    return "\n".join(lines)


def _section3_clients(period: str, restaurant_id: int) -> str:
    eng = get_engine()
    start_str, end_str = period.split("_")
    qg = (
        "SELECT SUM(new_customers) new, SUM(repeated_customers) rep, SUM(reactivated_customers) rea, SUM(total_customers) tot, "
        "SUM(earned_new_customers) enew, SUM(earned_repeated_customers) erep, SUM(earned_reactivated_customers) erea "
        "FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?"
    )
    qj = (
        "SELECT SUM(new_client) new, SUM(active_client) act, SUM(returned_client) ret "
        "FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?"
    )
    g = pd.read_sql_query(qg, eng, params=(restaurant_id, start_str, end_str)).iloc[0].fillna(0)
    j = pd.read_sql_query(qj, eng, params=(restaurant_id, start_str, end_str)).iloc[0].fillna(0)
    grab_new, grab_rep, grab_rea, grab_tot = int(g['new']), int(g['rep']), int(g['rea']), int(g['tot'])
    gojek_new, gojek_act, gojek_ret = int(j['new']), int(j['act']), int(j['ret'])
    total_unique = grab_tot + gojek_new + gojek_act + gojek_ret  # Ð²ÐµÑ€Ñ…Ð½ÑÑ Ð¾Ñ†ÐµÐ½ÐºÐ°

    lines = []
    lines.append("ðŸ‘¥ 3. Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— ÐšÐ›Ð˜Ð•ÐÐ¢Ð¡ÐšÐžÐ™ Ð‘ÐÐ—Ð«")
    lines.append("â€”" * 72)
    lines.append("ðŸ“Š Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ»Ð¸ÐµÐ½Ñ‚ÑÐºÐ¾Ð¹ Ð±Ð°Ð·Ñ‹ (GRAB + GOJEK):")
    lines.append(f"  ðŸ†• ÐÐ¾Ð²Ñ‹Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹: {grab_new + gojek_new}")
    lines.append(f"    ðŸ“± GRAB: {grab_new} | ðŸ›µ GOJEK: {gojek_new}")
    lines.append(f"  ðŸ”„ ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹: {grab_rep + gojek_act}")
    lines.append(f"    ðŸ“± GRAB: {grab_rep} | ðŸ›µ GOJEK: {gojek_act}")
    lines.append(f"  ðŸ“² Ð ÐµÐ°ÐºÑ‚Ð¸Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ: {grab_rea + gojek_ret}")
    lines.append(f"    ðŸ“± GRAB: {grab_rea} | ðŸ›µ GOJEK: {gojek_ret}")
    lines.append("")
    lines.append("ðŸ’° Ð”Ð¾Ñ…Ð¾Ð´Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ð¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð² (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ GRAB, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹):")
    lines.append(f"  ðŸ†• ÐÐ¾Ð²Ñ‹Ðµ: {_fmt_idr(g['enew'])}")
    lines.append(f"  ðŸ”„ ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ðµ: {_fmt_idr(g['erep'])}")
    lines.append(f"  ðŸ“² Ð ÐµÐ°ÐºÑ‚Ð¸Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ: {_fmt_idr(g['erea'])}")
    return "\n".join(lines)


def _section7_quality(quality: Dict) -> str:
    r = quality.get("ratings", {})
    lines = []
    lines.append("7. â­ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ðž ÐžÐ‘Ð¡Ð›Ð£Ð–Ð˜Ð’ÐÐÐ˜Ð¯ Ð˜ Ð£Ð”ÐžÐ’Ð›Ð•Ð¢Ð’ÐžÐ Ð•ÐÐÐžÐ¡Ð¢Ð¬ (GOJEK)")
    lines.append("â€”" * 72)
    total = r.get("total") or 0
    lines.append(f"ðŸ“Š Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾Ñ†ÐµÐ½Ð¾Ðº (Ð²ÑÐµÐ³Ð¾: {total}):")
    lines.append(f"  â­â­â­â­â­ 5 Ð·Ð²ÐµÐ·Ð´: {r.get('five',0)} ({_fmt_pct((r.get('five',0)/total*100) if total else None)})")
    lines.append(f"  â­â­â­â­ 4 Ð·Ð²ÐµÐ·Ð´Ñ‹: {r.get('four',0)} ({_fmt_pct((r.get('four',0)/total*100) if total else None)})")
    lines.append(f"  â­â­â­ 3 Ð·Ð²ÐµÐ·Ð´Ñ‹: {r.get('three',0)} ({_fmt_pct((r.get('three',0)/total*100) if total else None)})")
    lines.append(f"  â­â­ 2 Ð·Ð²ÐµÐ·Ð´Ñ‹: {r.get('two',0)} ({_fmt_pct((r.get('two',0)/total*100) if total else None)})")
    lines.append(f"  â­ 1 Ð·Ð²ÐµÐ·Ð´Ð°: {r.get('one',0)} ({_fmt_pct((r.get('one',0)/total*100) if total else None)})")
    lines.append("")
    lines.append(f"ðŸ“ˆ Ð˜Ð½Ð´ÐµÐºÑ ÑƒÐ´Ð¾Ð²Ð»ÐµÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸: {_fmt_rate(r.get('satisfaction_index'))}/5.0")
    lines.append(f"ðŸš¨ ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ñ‹ (1-2â˜…): {r.get('negative_1_2',{}).get('count',0)} ({_fmt_pct(r.get('negative_1_2',{}).get('percent'))})")
    lines.append("")
    lines.append("ðŸ“Š Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° Ð¿Ð»Ð¾Ñ…Ð¸Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº (Ð½Ðµ 5â˜…):")
    lines.append(f"  ðŸ“ˆ ÐŸÐ»Ð¾Ñ…Ð¸Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð²ÑÐµÐ³Ð¾: {r.get('not_five',{}).get('count',0)} Ð¸Ð· {total} ({_fmt_pct(r.get('not_five',{}).get('percent'))})")
    lines.append(f"  ðŸ“¦ Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ð·Ð°ÐºÐ°Ð·Ð¾Ð² GOJEK Ð½Ð° 1 Ð¿Ð»Ð¾Ñ…ÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ: {_fmt_rate(quality.get('orders_per_not_five_rating'))}")
    return "\n".join(lines)


def _fmt_minutes_to_hhmmss(mins: Optional[float]) -> str:
    if mins is None or (isinstance(mins, float) and np.isnan(mins)):
        return "â€”"
    try:
        total_seconds = int(round(float(mins) * 60))
        h = total_seconds // 3600
        m = (total_seconds % 3600) // 60
        s = total_seconds % 60
        return f"{h}:{m:02d}:{s:02d}"
    except Exception:
        return "â€”"


def _categorize_feature(name: str) -> str:
    n = name.lower()
    if n.startswith("mkt_") or "ads_spend" in n or "impressions" in n or "roas" in n:
        return "Marketing"
    if n.startswith("ops_") or any(k in n for k in ["accepting_time", "preparation_time", "delivery_time", "outage_", "offline_"]):
        return "Operations"
    if n in ("temp", "rain", "wind", "humidity", "tourist_flow", "is_holiday", "day_of_week", "is_weekend") or any(k in n for k in ["temp_", "rain_", "wind_", "humidity_", "tourist_flow_"]):
        return "External"
    if "rating" in n:
        return "Quality"
    return "Other"


def _pretty_feature_name(name: str) -> str:
    n = name.lower()
    mapping = {
        # Marketing
        "mkt_roas_grab": "ROAS (GRAB)",
        "mkt_roas_gojek": "ROAS (GOJEK)",
        "mkt_ads_spend_grab": "Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ð¹ Ð±ÑŽÐ´Ð¶ÐµÑ‚ (GRAB)",
        "mkt_ads_spend_gojek": "Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ð¹ Ð±ÑŽÐ´Ð¶ÐµÑ‚ (GOJEK)",
        "ads_spend_total": "Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ð¹ Ð±ÑŽÐ´Ð¶ÐµÑ‚ (ÑÑƒÐ¼Ð¼Ð°Ñ€Ð½Ð¾)",
        "impressions_total": "ÐŸÐ¾ÐºÐ°Ð·Ñ‹ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹",
        # Operations (Ð¾Ð±Ñ‰Ð¸Ðµ)
        "preparation_time_mean": "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ (Ð¼Ð¸Ð½)",
        "accepting_time_mean": "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ (Ð¼Ð¸Ð½)",
        "delivery_time_mean": "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸ (Ð¼Ð¸Ð½)",
        # Operations (GOJEK)
        "ops_preparation_time_gojek": "GOJEK: Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ",
        "ops_accepting_time_gojek": "GOJEK: Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ",
        "ops_delivery_time_gojek": "GOJEK: Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸",
        # Outage/offline
        "outage_offline_rate_grab": "GRAB: Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½ (Ð¼Ð¸Ð½)",
        "offline_rate_grab": "GRAB: Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½ (Ð¼Ð¸Ð½)",
        # External
        "rain": "Ð”Ð¾Ð¶Ð´ÑŒ (Ð¼Ð¼)",
        "temp": "Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° (Â°C)",
        "wind": "Ð’ÐµÑ‚ÐµÑ€",
        "humidity": "Ð’Ð»Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ (%)",
        "tourist_flow": "Ð¢ÑƒÑ€Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº",
        "is_holiday": "ÐŸÑ€Ð°Ð·Ð´Ð½Ð¸Ðº",
        "day_of_week": "Ð”ÐµÐ½ÑŒ Ð½ÐµÐ´ÐµÐ»Ð¸",
        "is_weekend": "Ð’Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹",
        # Quality
        "rating": "Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³",
    }
    if n in mapping:
        return mapping[n]
    # Heuristics: platform/time metrics
    if n.startswith("ops_preparation_time_"):
        plat = n.split("_")[-1].upper()
        return f"{plat}: Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ"
    if n.startswith("ops_accepting_time_"):
        plat = n.split("_")[-1].upper()
        return f"{plat}: Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ"
    if n.startswith("ops_delivery_time_"):
        plat = n.split("_")[-1].upper()
        return f"{plat}: Ð²Ñ€ÐµÐ¼Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸"
    if n.startswith("mkt_roas_"):
        plat = n.split("_")[-1].upper()
        return f"ROAS ({plat})"
    if n.startswith("mkt_ads_spend_"):
        plat = n.split("_")[-1].upper()
        return f"Ð ÐµÐºÐ»Ð°Ð¼Ð½Ñ‹Ð¹ Ð±ÑŽÐ´Ð¶ÐµÑ‚ ({plat})"
    # Fallback: make readable
    pretty = name.replace("_", " ")
    pretty = pretty.replace("grab", "GRAB").replace("gojek", "GOJEK").replace("roas", "ROAS")
    return pretty


def _section8_critical_days_ml(period: str, restaurant_id: int) -> str:
    try:
        start_str, end_str = period.split("_")
        df = pd.read_csv("/workspace/data/merged_dataset.csv", parse_dates=["date"])  # daily rows per restaurant
        sub = df[(df["restaurant_id"] == restaurant_id) & (df["date"] >= start_str) & (df["date"] <= end_str)].copy()
        if sub.empty:
            return "8. ðŸš¨ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð”ÐÐ˜ (ML)\n" + ("â€”" * 72) + "\nÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´."

        # Median per day and critical threshold (â‰¤ -30% Ðº Ð¼ÐµÐ´Ð¸Ð°Ð½Ðµ)
        daily = sub.groupby("date", as_index=False)["total_sales"].sum().sort_values("date")
        med = float(daily["total_sales"].median()) if len(daily) else 0.0
        thr = 0.7 * med
        critical_dates = daily.loc[daily["total_sales"] <= thr, "date"].dt.normalize().tolist()

        lines: list[str] = []
        lines.append("8. ðŸš¨ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð”ÐÐ˜ (ML)")
        lines.append("â€”" * 72)
        def _expected_baseline_for_day(daily_df: pd.DataFrame, d: pd.Timestamp) -> float:
            try:
                dow = int(d.dayofweek)
                window = daily_df[daily_df['date'] < d].tail(56)
                same_dow = window[window['date'].dt.dayofweek == dow]
                series = same_dow['total_sales'] if not same_dow.empty else window['total_sales']
                if series.empty:
                    series = daily_df['total_sales']
                return float(series.median()) if not series.empty else 0.0
            except Exception:
                return 0.0
        if not critical_dates:
            lines.append("Ð’ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ðµ Ð½ÐµÑ‚ Ð´Ð½ÐµÐ¹ Ñ Ð¿Ð°Ð´ÐµÐ½Ð¸ÐµÐ¼ â‰¥ 30% Ðº Ð¼ÐµÐ´Ð¸Ð°Ð½Ðµ.")
            # Ð”Ð¾Ð±Ð°Ð²Ð¸Ð¼ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð½Ñ‹Ð¹ ÑÑ€ÐµÐ· Ð¿Ð¾ Ð´Ð¾Ð¶Ð´ÑŽ/Ð¿Ñ€Ð°Ð·Ð´Ð½Ð¸ÐºÐ°Ð¼ Ð´Ð»Ñ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°
            sub['heavy_rain'] = (sub['rain'].fillna(0.0) >= 10.0).astype(int)
            def _mean(series):
                s = pd.to_numeric(series, errors='coerce')
                return float(s.mean()) if len(s) else 0.0
            by_rain = sub.groupby('heavy_rain')['total_sales'].mean().to_dict()
            if 0 in by_rain:
                dr = (by_rain.get(1, by_rain[0]) - by_rain[0]) / (by_rain[0] or 1.0) * 100.0
                lines.append(f"ðŸŒ§ï¸ Ð­Ñ„Ñ„ÐµÐºÑ‚ Ð´Ð¾Ð¶Ð´Ñ (Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° ÑÑ€ÐµÐ´Ð½Ð¸Ñ…): {_fmt_pct(dr)}")
            by_h = sub.groupby(sub['is_holiday'].fillna(0).astype(int))['total_sales'].mean().to_dict()
            if 0 in by_h:
                dh = (by_h.get(1, by_h[0]) - by_h[0]) / (by_h[0] or 1.0) * 100.0
                lines.append(f"ðŸŽŒ Ð­Ñ„Ñ„ÐµÐºÑ‚ Ð¿Ñ€Ð°Ð·Ð´Ð½Ð¸ÐºÐ¾Ð² (Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° ÑÑ€ÐµÐ´Ð½Ð¸Ñ…): {_fmt_pct(dh)}")
            return "\n".join(lines)

        # Prepare SHAP per-row
        model, features, background = load_artifacts()
        X = sub[features]
        pre = model.named_steps["pre"]
        mdl = model.named_steps["model"]
        X_pre = pre.transform(X)
        try:
            if background is not None and not background.empty:
                bg_pre = pre.transform(background[features])
                explainer = shap.TreeExplainer(mdl, data=bg_pre, feature_perturbation="interventional")
            else:
                explainer = shap.TreeExplainer(mdl, feature_perturbation="interventional")
            shap_values = explainer.shap_values(X_pre)
        except Exception:
            explainer = shap.TreeExplainer(mdl)
            shap_values = explainer.shap_values(X_pre)

        _, groups = _resolve_preprocessed_feature_groups(pre)
        # Exclude trivial features
        pat = [re.compile(r"^orders_count(?!.*conversion).*"), re.compile(r"^total_sales.*"), re.compile(r"^restaurant_id$")]
        def is_excluded(n: str) -> bool:
            return any(p.search(n) for p in pat)

        eng = get_engine()
        # Period baselines (Ð´Ð»Ñ Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÐºÐ¸Ñ… Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ð¹)
        qg_all = pd.read_sql_query(
            "SELECT stat_date, ads_spend, ads_sales, cancelled_orders, offline_rate FROM grab_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
            eng, params=(restaurant_id, start_str, end_str)
        )
        qj_all = pd.read_sql_query(
            "SELECT stat_date, ads_spend, ads_sales, accepting_time, preparation_time, delivery_time, close_time, cancelled_orders FROM gojek_stats WHERE restaurant_id=? AND stat_date BETWEEN ? AND ?",
            eng, params=(restaurant_id, start_str, end_str)
        )
        qg_all['stat_date'] = pd.to_datetime(qg_all['stat_date'], errors='coerce').dt.date
        qj_all['stat_date'] = pd.to_datetime(qj_all['stat_date'], errors='coerce').dt.date
        def _to_min_p(v):
            if v is None:
                return None
            s = str(v)
            parts = s.split(":")
            try:
                if len(parts) == 3:
                    h, m, sec = parts
                    return int(h) * 60 + int(m) + int(sec) / 60.0
            except Exception:
                pass
            try:
                return float(s)
            except Exception:
                return None
        def _safe_mean(series):
            s = pd.to_numeric(series, errors='coerce').dropna()
            return float(s.mean()) if not s.empty else None
        # Baselines
        spend_g_avg = _safe_mean(qg_all.get('ads_spend'))
        spend_j_avg = _safe_mean(qj_all.get('ads_spend'))
        roas_g_avg = None
        if not qg_all.empty:
            tmp = []
            for _, r in qg_all.iterrows():
                a, s_ = r.get('ads_spend'), r.get('ads_sales')
                try:
                    a = float(a); s_ = float(s_)
                    if a > 0:
                        tmp.append(s_ / a)
                except Exception:
                    pass
            roas_g_avg = float(np.mean(tmp)) if tmp else None
        roas_j_avg = None
        if not qj_all.empty:
            tmp = []
            for _, r in qj_all.iterrows():
                a, s_ = r.get('ads_spend'), r.get('ads_sales')
                try:
                    a = float(a); s_ = float(s_)
                    if a > 0:
                        tmp.append(s_ / a)
                except Exception:
                    pass
            roas_j_avg = float(np.mean(tmp)) if tmp else None
        canc_g_avg = _safe_mean(qg_all.get('cancelled_orders'))
        canc_j_avg = _safe_mean(qj_all.get('cancelled_orders'))
        off_g_avg = _safe_mean(qg_all.get('offline_rate'))
        prep_avg = _safe_mean(qj_all.get('preparation_time').apply(_to_min_p)) if 'preparation_time' in qj_all.columns else None
        accept_avg = _safe_mean(qj_all.get('accepting_time').apply(_to_min_p)) if 'accepting_time' in qj_all.columns else None
        deliv_avg = _safe_mean(qj_all.get('delivery_time').apply(_to_min_p)) if 'delivery_time' in qj_all.columns else None

        for d in critical_dates:
            day_mask = sub["date"].dt.normalize() == d
            idxs = np.where(day_mask.values)[0]
            if len(idxs) == 0:
                continue
            # Aggregate contributions over all rows of that date (should typically be 1 per date)
            contrib_sum: Dict[str, float] = {}
            for i in idxs:
                for feat, cols in groups.items():
                    if is_excluded(feat):
                        continue
                    if not cols:
                        continue
                    val = float(np.sum(shap_values[i, cols]))
                    contrib_sum[feat] = contrib_sum.get(feat, 0.0) + val
            # Select significant factors by |impact|: cover ~95% cumulatively and include any with share >=1%
            contrib_sorted = sorted(contrib_sum.items(), key=lambda x: abs(x[1]), reverse=True)
            total_abs = sum(abs(v) for v in contrib_sum.values()) or 1.0
            selected = []
            cum = 0.0
            for feat, val in contrib_sorted:
                share = abs(val) / total_abs
                if share >= 0.01 or cum < 0.95:
                    selected.append((feat, val))
                    cum += share
                else:
                    break

            # Group shares
            group_shares: Dict[str, float] = {}
            for feat, val in contrib_sum.items():
                cat = _categorize_feature(feat)
                group_shares[cat] = group_shares.get(cat, 0.0) + abs(val)
            for k in list(group_shares.keys()):
                group_shares[k] = round(100.0 * group_shares[k] / total_abs, 1)

            # Day-level raw details from stats
            ds = str(d.date())
            qg = pd.read_sql_query(
                "SELECT sales, orders, ads_spend, ads_sales, offline_rate, cancelled_orders FROM grab_stats WHERE restaurant_id=? AND stat_date=?",
                eng, params=(restaurant_id, ds)
            )
            qj = pd.read_sql_query(
                "SELECT sales, orders, ads_spend, ads_sales, accepting_time, preparation_time, delivery_time, close_time, cancelled_orders FROM gojek_stats WHERE restaurant_id=? AND stat_date=?",
                eng, params=(restaurant_id, ds)
            )
            grab_off_mins = float(qg.iloc[0]["offline_rate"]) if (not qg.empty and pd.notna(qg.iloc[0]["offline_rate"])) else None
            gojek_close = str(qj.iloc[0]["close_time"]) if (not qj.empty and pd.notna(qj.iloc[0]["close_time"])) else ""
            # close_time may be HH:MM:SS
            def _hms_close(s: str) -> str:
                parts = s.split(":") if s else []
                try:
                    if len(parts) == 3:
                        h, m, sec = parts
                        return f"{int(h)}:{int(m):02d}:{int(sec):02d}"
                except Exception:
                    pass
                return "â€”"

            # Weather/holiday from dataset row (first match of the date)
            row = sub.loc[day_mask].iloc[0]
            rain = float(row.get("rain")) if pd.notna(row.get("rain")) else None
            temp = float(row.get("temp")) if pd.notna(row.get("temp")) else None
            wind = float(row.get("wind")) if pd.notna(row.get("wind")) else None
            hum = float(row.get("humidity")) if pd.notna(row.get("humidity")) else None
            is_hol = int(row.get("is_holiday")) if pd.notna(row.get("is_holiday")) else 0
            total_sales_day = float(daily.loc[daily["date"] == d, "total_sales"].iloc[0])
            delta_pct = ((total_sales_day - med) / med * 100.0) if med else None
            expected_idr = _expected_baseline_for_day(daily, d)
            drop_idr = max(0.0, expected_idr - total_sales_day)

            lines.append(f"ðŸ“‰ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ Ð”Ð•ÐÐ¬: {ds} (Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°: {_fmt_idr(total_sales_day)}; Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ Ðº Ð¼ÐµÐ´Ð¸Ð°Ð½Ðµ: {_fmt_pct(delta_pct)})")
            lines.append("â€”" * 72)
            # Compute business-oriented factor sets (threshold 3%)
            def _share(v: float) -> float:
                return round(100.0 * abs(v) / total_abs, 1)
            def _is_technical(name: str) -> bool:
                n = name.lower()
                return ('lag' in n) or ('rolling' in n)
            sig_all = [(f, v, _share(v)) for f, v in selected if _share(v) >= 3.0]
            sig = [(f, v, s) for f, v, s in sig_all if not _is_technical(f)] or sig_all
            neg = [(f, v, s) for f, v, s in sig if v < 0]
            pos = [(f, v, s) for f, v, s in sig if v > 0]
            neg = sorted(neg, key=lambda x: x[2], reverse=True)[:5]
            pos = sorted(pos, key=lambda x: x[2], reverse=True)[:2]

            # Compute monetary effect for negative factors and deduplicate
            neg_total_abs = sum(abs(v) for f, v in contrib_sum.items() if v < 0) or 1.0
            factor_rows_neg = []
            seen_canon: set[str] = set()
            def _canon(name: str) -> str:
                n = name.lower()
                n = n.replace("preparation_time_mean","preparation_time").replace("accepting_time_mean","accepting_time").replace("delivery_time_mean","delivery_time")
                return n
            for f, v, s in neg:
                canon = _canon(f)
                if canon in seen_canon:
                    continue
                seen_canon.add(canon)
                money = round((abs(v) / neg_total_abs) * drop_idr)
                if s < 5.0 and money < 50000:
                    continue
                factor_rows_neg.append((f, s, money))

            # Day-level metrics snapshot for comments
            # Build baselines already computed above: roas_g_avg, roas_j_avg, prep/accept/deliv avg, etc.
            day_roas_g = None; day_roas_j = None; day_spend_g = None; day_spend_j = None
            if not qg.empty:
                gs = qg.iloc[0]
                day_spend_g = float(gs.get('ads_spend')) if pd.notna(gs.get('ads_spend')) else None
                day_roas_g = (float(gs.get('ads_sales')) / float(gs.get('ads_spend'))) if (pd.notna(gs.get('ads_spend')) and float(gs.get('ads_spend'))>0) else None
            if not qj.empty:
                js = qj.iloc[0]
                day_spend_j = float(js.get('ads_spend')) if pd.notna(js.get('ads_spend')) else None
                day_roas_j = (float(js.get('ads_sales')) / float(js.get('ads_spend'))) if (pd.notna(js.get('ads_spend')) and float(js.get('ads_spend'))>0) else None
            d_prep = _to_min_p(qj.iloc[0].get('preparation_time')) if not qj.empty else None
            d_acc = _to_min_p(qj.iloc[0].get('accepting_time')) if not qj.empty else None
            d_del = _to_min_p(qj.iloc[0].get('delivery_time')) if not qj.empty else None

            def _comment_for(feat_name: str, is_positive: bool) -> str:
                n = feat_name.lower()
                # Marketing
                if 'roas' in n:
                    # choose platform
                    if 'grab' in n and day_roas_g is not None and roas_g_avg is not None:
                        return f"Ñ€ÐµÐºÐ»Ð°Ð¼Ð° GRAB {'ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°' if is_positive else 'Ð½ÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°'} ({day_roas_g:.2f}x vs {roas_g_avg:.2f}x)"
                    if 'gojek' in n and day_roas_j is not None and roas_j_avg is not None:
                        return f"Ñ€ÐµÐºÐ»Ð°Ð¼Ð° GOJEK {'ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°' if is_positive else 'Ð½ÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°'} ({day_roas_j:.2f}x vs {roas_j_avg:.2f}x)"
                    return "Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð°Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð½Ð¸Ð¶Ðµ Ð½Ð¾Ñ€Ð¼Ñ‹" if not is_positive else "Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð°Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð²Ñ‹ÑˆÐµ Ð½Ð¾Ñ€Ð¼Ñ‹"
                if 'ads_spend' in n or 'budget' in n:
                    if 'grab' in n and day_spend_g is not None and spend_g_avg is not None:
                        return f"Ð±ÑŽÐ´Ð¶ÐµÑ‚ GRAB {'Ð²Ñ‹ÑˆÐµ' if is_positive else 'Ð½Ð¸Ð¶Ðµ'} ÑÑ€ÐµÐ´Ð½ÐµÐ³Ð¾ ({_fmt_idr(day_spend_g)} vs {_fmt_idr(spend_g_avg)})"
                    if 'gojek' in n and day_spend_j is not None and spend_j_avg is not None:
                        return f"Ð±ÑŽÐ´Ð¶ÐµÑ‚ GOJEK {'Ð²Ñ‹ÑˆÐµ' if is_positive else 'Ð½Ð¸Ð¶Ðµ'} ÑÑ€ÐµÐ´Ð½ÐµÐ³Ð¾ ({_fmt_idr(day_spend_j)} vs {_fmt_idr(spend_j_avg)})"
                    return "Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð¾Ð¹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸"
                # Operations
                if 'preparation_time' in n:
                    if d_prep is not None and prep_avg is not None:
                        return f"Ð²Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ {'Ð½Ð¸Ð¶Ðµ' if is_positive else 'Ð²Ñ‹ÑˆÐµ'} Ð½Ð¾Ñ€Ð¼Ñ‹ ({d_prep:.1f} vs {prep_avg:.1f} Ð¼Ð¸Ð½)"
                    return "ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ"
                if 'accepting_time' in n:
                    if d_acc is not None and accept_avg is not None:
                        return f"Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ {'Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ' if is_positive else 'Ð´Ð¾Ð»ÑŒÑˆÐµ'} Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð³Ð¾ ({d_acc:.1f} vs {accept_avg:.1f} Ð¼Ð¸Ð½)"
                    return "ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ"
                if 'delivery_time' in n:
                    if d_del is not None and deliv_avg is not None:
                        return f"Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ° {'Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ' if is_positive else 'Ð´Ð¾Ð»ÑŒÑˆÐµ'} Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð³Ð¾ ({d_del:.1f} vs {deliv_avg:.1f} Ð¼Ð¸Ð½)"
                    return "ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸"
                if 'offline' in n or 'outage' in n:
                    return "Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð° Ð±Ñ‹Ð»Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° (Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½)"
                # External
                if 'rain' in n:
                    return "Ð´Ð¾Ð¶Ð´ÑŒ ÑÐ½Ð¸Ð·Ð¸Ð» ÑÐ¿Ñ€Ð¾Ñ" if not is_positive else "Ð¿Ð¾Ð³Ð¾Ð´Ð° Ð±Ð»Ð°Ð³Ð¾Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð°"
                if 'day_of_week' in n or 'weekend' in n:
                    return "ÑÐ»Ð°Ð±Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ Ð½ÐµÐ´ÐµÐ»Ð¸" if not is_positive else "ÑÐ¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ Ð½ÐµÐ´ÐµÐ»Ð¸"
                if 'humidity' in n or 'wind' in n or 'temp' in n:
                    return "Ð¿Ð¾Ð³Ð¾Ð´Ð½Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ ÑÐ½Ð¸Ð·Ð¸Ð»Ð¸ ÑÐ¿Ñ€Ð¾Ñ" if not is_positive else "Ð¿Ð¾Ð³Ð¾Ð´Ð½Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð¿Ð¾Ð¼Ð¾Ð³Ð»Ð¸"
                if 'rating' in n:
                    return "Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ» Ð½Ð° ÑÐ¿Ñ€Ð¾Ñ"
                return "Ð²Ð»Ð¸ÑÑŽÑ‰Ð¸Ð¹ Ñ„Ð°ÐºÑ‚Ð¾Ñ€ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°"

            # Short summary (business-oriented)
            lines.append("ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ:")
            lines.append(f"- ÐŸÑ€Ð¾ÑÐ°Ð´ÐºÐ°: âˆ’{_fmt_idr(drop_idr)} ({_fmt_pct(delta_pct)} Ðº Ð¼ÐµÐ´Ð¸Ð°Ð½Ðµ/Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸ÑŽ).")
            if 'factor_rows_neg' in locals() and factor_rows_neg:
                topn = ", ".join([f"{_pretty_feature_name(f)} (âˆ’{_fmt_idr(m)})" for f, _, m in factor_rows_neg[:2]])
                lines.append(f"- Ð“Ð»Ð°Ð²Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹: {topn}.")
            if grab_off_mins and grab_off_mins > 0:
                lines.append(f"- Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ: Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½ GRAB {_fmt_minutes_to_hhmmss(grab_off_mins)}.")
            if rain and rain > 0:
                lines.append(f"- ÐŸÐ¾Ð³Ð¾Ð´Ð°: Ð´Ð¾Ð¶Ð´ÑŒ {rain} Ð¼Ð¼ ÑÐ½Ð¸Ð·Ð¸Ð» Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ.")
            lines.append("")

            # Factors tables (negatives first)
            if 'factor_rows_neg' in locals() and factor_rows_neg:
                lines.append("ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹ (Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ):")
                lines.append("| Ð¤Ð°ÐºÑ‚Ð¾Ñ€ | Ð’ÐºÐ»Ð°Ð´ | ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ |")
                lines.append("|---|---:|---|")
                for f, s, money in sorted(factor_rows_neg, key=lambda x: (x[2], x[1]), reverse=True)[:10]:
                    lines.append(f"| {_pretty_feature_name(f)} | âˆ’{_fmt_idr(money)} ({s}%) | {_comment_for(f, False)} |")
                # Grouped diagnostics by category (top 2â€“3 per category, â‰¥2%)
                cat_rows = {}
                for f, s, money in factor_rows_neg:
                    cat = _categorize_feature(f)
                    cat_rows.setdefault(cat, []).append((f, s, money))
                lines.append("")
                lines.append("Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð¾Ð² (Ð¿Ð¾ Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ð¼):")
                for cat in ["Marketing", "Operations", "External"]:
                    rows = sorted(cat_rows.get(cat, []), key=lambda x: (x[2], x[1]), reverse=True)
                    rows = [r for r in rows if r[1] >= 2.0][:3]
                    if rows:
                        lines.append(f"  â€¢ {cat}:")
                        for f, s, money in rows:
                            lines.append(f"    - {_pretty_feature_name(f)}: âˆ’{_fmt_idr(money)} ({s}%)")
                lines.append("")
            if pos:
                lines.append("Ð§Ñ‚Ð¾ Ð¿Ð¾Ð¼Ð¾Ð³Ð»Ð¾ (Ð´Ð¾ 2 Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð¾Ð²):")
                lines.append("| Ð¤Ð°ÐºÑ‚Ð¾Ñ€ | Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ | ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ |")
                lines.append("|---|---:|---|")
                for f, v, s in pos:
                    lines.append(f"| {_pretty_feature_name(f)} | {s}% | {_comment_for(f, True)} |")
                lines.append("")

            lines.append("ðŸ“Š Ð’ÐºÐ»Ð°Ð´ Ð³Ñ€ÑƒÐ¿Ð¿ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð¾Ð²:")
            for cat in ["Operations", "Marketing", "External", "Quality", "Other"]:
                if cat in group_shares:
                    lines.append(f"  â€¢ {cat}: {group_shares[cat]}%")
            lines.append("")
            lines.append("ðŸ“… ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð½Ñ:")
            # Platforms/offline
            lines.append(f"  â€¢ ðŸ“± GRAB Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½: {_fmt_minutes_to_hhmmss(grab_off_mins)}")
            lines.append(f"  â€¢ ðŸ›µ GOJEK Ð¾Ñ„Ñ„Ð»Ð°Ð¹Ð½: {_hms_close(gojek_close)}")
            # Marketing
            if not qg.empty:
                gs = qg.iloc[0]
                roas_g = (float(gs["ads_sales"]) / float(gs["ads_spend"])) if (pd.notna(gs["ads_spend"]) and float(gs["ads_spend"])>0) else None
                lines.append(f"  â€¢ ðŸŽ¯ GRAB: spend {_fmt_idr(gs['ads_spend'])}, ROAS {_fmt_rate(roas_g)}x")
            if not qj.empty:
                js = qj.iloc[0]
                roas_j = (float(js["ads_sales"]) / float(js["ads_spend"])) if (pd.notna(js["ads_spend"]) and float(js["ads_spend"])>0) else None
                lines.append(f"  â€¢ ðŸŽ¯ GOJEK: spend {_fmt_idr(js['ads_spend'])}, ROAS {_fmt_rate(roas_j)}x")
            # Operations (GOJEK times)
            if not qj.empty:
                def _to_min(v):
                    s = str(v)
                    parts = s.split(":")
                    try:
                        if len(parts) == 3:
                            h, m, sec = parts
                            return int(h)*60 + int(m) + int(sec)/60.0
                    except Exception:
                        return None
                    try:
                        return float(s)
                    except Exception:
                        return None
                lines.append(f"  â€¢ â±ï¸ ÐŸÑ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ: {_fmt_rate(_to_min(qj.iloc[0].get('preparation_time')))} Ð¼Ð¸Ð½")
                lines.append(f"  â€¢ â³ ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ: {_fmt_rate(_to_min(qj.iloc[0].get('accepting_time')))} Ð¼Ð¸Ð½")
                lines.append(f"  â€¢ ðŸš— Ð”Ð¾ÑÑ‚Ð°Ð²ÐºÐ°: {_fmt_rate(_to_min(qj.iloc[0].get('delivery_time')))} Ð¼Ð¸Ð½")
            # Weather/holiday
            lines.append(f"  â€¢ ðŸŒ§ï¸ Ð”Ð¾Ð¶Ð´ÑŒ: {rain if rain is not None else 'â€”'} Ð¼Ð¼; ðŸŒ¡ï¸ Ð¢ÐµÐ¼Ð¿.: {temp if temp is not None else 'â€”'}Â°C; ðŸŒ¬ï¸ Ð’ÐµÑ‚ÐµÑ€: {wind if wind is not None else 'â€”'}; ðŸ’§Ð’Ð»Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ: {hum if hum is not None else 'â€”'}")
            lines.append(f"  â€¢ ðŸŽŒ ÐŸÑ€Ð°Ð·Ð´Ð½Ð¸Ðº: {'Ð´Ð°' if is_hol else 'Ð½ÐµÑ‚'}")
            lines.append("")

            # Human-friendly explanations with evidence
            try:
                lines.append("ðŸ§  ÐŸÐ¾ÑÑÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼Ð¸ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸:")
                # Compute last 7 days baseline before current day
                last7_g = qg_all[qg_all['stat_date'] < pd.to_datetime(ds)].tail(7)
                last7_j = qj_all[qj_all['stat_date'] < pd.to_datetime(ds)].tail(7)
                roas_g_last7 = None; roas_j_last7 = None
                if not last7_g.empty:
                    tmp=[]
                    for _, r in last7_g.iterrows():
                        a, s_ = r.get('ads_spend'), r.get('ads_sales')
                        try:
                            a=float(a); s_=float(s_)
                            if a>0: tmp.append(s_/a)
                        except Exception:
                            pass
                    roas_g_last7 = float(np.mean(tmp)) if tmp else None
                if not last7_j.empty:
                    tmp=[]
                    for _, r in last7_j.iterrows():
                        a, s_ = r.get('ads_spend'), r.get('ads_sales')
                        try:
                            a=float(a); s_=float(s_)
                            if a>0: tmp.append(s_/a)
                        except Exception:
                            pass
                    roas_j_last7 = float(np.mean(tmp)) if tmp else None
                # Best day in period for operational comparison
                best_row = daily.sort_values('total_sales', ascending=False).iloc[0] if not daily.empty else None
                best_ds = str(pd.to_datetime(best_row['date']).date()) if best_row is not None else None
                qj_best = pd.read_sql_query(
                    "SELECT preparation_time, accepting_time, delivery_time FROM gojek_stats WHERE restaurant_id=? AND stat_date=?",
                    eng, params=(restaurant_id, best_ds)
                ) if best_ds else pd.DataFrame()

                # Marketing evidence
                if not qg.empty:
                    gs = qg.iloc[0]
                    day_spend_g = float(gs.get('ads_spend')) if pd.notna(gs.get('ads_spend')) else None
                    day_roas_g = (float(gs.get('ads_sales')) / float(gs.get('ads_spend'))) if (pd.notna(gs.get('ads_spend')) and float(gs.get('ads_spend'))>0) else None
                    if day_roas_g is not None and roas_g_avg is not None:
                        diff = (day_roas_g - roas_g_avg) / (roas_g_avg or 1.0) * 100.0
                        extra = f"; vs Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¹ Ð½ÐµÐ´ÐµÐ»Ð¸ {roas_g_last7:.2f}x" if roas_g_last7 is not None else ""
                        lines.append(f"  â€¢ ROAS GRAB {day_roas_g:.2f}x Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {roas_g_avg:.2f}x ({diff:+.0f}%){extra}.")
                    if day_spend_g is not None and spend_g_avg is not None:
                        diff = (day_spend_g - spend_g_avg) / (spend_g_avg or 1.0) * 100.0
                        lines.append(f"  â€¢ Ð‘ÑŽÐ´Ð¶ÐµÑ‚ GRAB {('Ð½Ð¸Ð¶Ðµ' if diff<0 else 'Ð²Ñ‹ÑˆÐµ')} Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹: {_fmt_idr(day_spend_g)} vs {_fmt_idr(spend_g_avg)} ({diff:+.0f}%).")
                if not qj.empty:
                    js = qj.iloc[0]
                    day_spend_j = float(js.get('ads_spend')) if pd.notna(js.get('ads_spend')) else None
                    day_roas_j = (float(js.get('ads_sales')) / float(js.get('ads_spend'))) if (pd.notna(js.get('ads_spend')) and float(js.get('ads_spend'))>0) else None
                    if day_roas_j is not None and roas_j_avg is not None:
                        diff = (day_roas_j - roas_j_avg) / (roas_j_avg or 1.0) * 100.0
                        extra = f"; vs Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¹ Ð½ÐµÐ´ÐµÐ»Ð¸ {roas_j_last7:.2f}x" if roas_j_last7 is not None else ""
                        lines.append(f"  â€¢ ROAS GOJEK {day_roas_j:.2f}x Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {roas_j_avg:.2f}x ({diff:+.0f}%) {extra}.")
                    if day_spend_j is not None and spend_j_avg is not None:
                        diff = (day_spend_j - spend_j_avg) / (spend_j_avg or 1.0) * 100.0
                        lines.append(f"  â€¢ Ð‘ÑŽÐ´Ð¶ÐµÑ‚ GOJEK {('Ð½Ð¸Ð¶Ðµ' if diff<0 else 'Ð²Ñ‹ÑˆÐµ')} Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹: {_fmt_idr(day_spend_j)} vs {_fmt_idr(spend_j_avg)} ({diff:+.0f}%).")
                # Operations evidence with best-day reference
                if not qj.empty:
                    js = qj.iloc[0]
                    d_prep = _to_min_p(js.get('preparation_time'))
                    d_acc = _to_min_p(js.get('accepting_time'))
                    d_del = _to_min_p(js.get('delivery_time'))
                    best_prep = _to_min_p(qj_best.iloc[0].get('preparation_time')) if not qj_best.empty else None
                    if d_prep is not None and prep_avg is not None:
                        diff = (d_prep - prep_avg) / (prep_avg or 1.0) * 100.0
                        tail = f"; Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð´ÐµÐ½ÑŒ: {best_prep:.1f} Ð¼Ð¸Ð½" if best_prep is not None else ""
                        lines.append(f"  â€¢ ÐŸÑ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ {d_prep:.1f} Ð¼Ð¸Ð½ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {prep_avg:.1f} Ð¼Ð¸Ð½ ({diff:+.0f}%){tail}.")
                    if d_acc is not None and accept_avg is not None:
                        diff = (d_acc - accept_avg) / (accept_avg or 1.0) * 100.0
                        lines.append(f"  â€¢ ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ {d_acc:.1f} Ð¼Ð¸Ð½ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² {accept_avg:.1f} Ð¼Ð¸Ð½ ({diff:+.0f}%).")
                    if d_del is not None and deliv_avg is not None:
                        diff = (d_del - deliv_avg) / (deliv_avg or 1.0) * 100.0
                        lines.append(f"  â€¢ Ð”Ð¾ÑÑ‚Ð°Ð²ÐºÐ° {d_del:.1f} Ð¼Ð¸Ð½ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² {deliv_avg:.1f} Ð¼Ð¸Ð½ ({diff:+.0f}%).")
                # Availability evidence
                if grab_off_mins is not None and off_g_avg is not None:
                    diff = (grab_off_mins - off_g_avg) / (off_g_avg or 1.0) * 100.0
                    lines.append(f"  â€¢ ÐžÑ„Ñ„Ð»Ð°Ð¹Ð½ GRAB: {_fmt_minutes_to_hhmmss(grab_off_mins)} Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {_fmt_minutes_to_hhmmss(off_g_avg)} ({diff:+.0f}%).")
                # Cancellations
                if not qg.empty and canc_g_avg is not None:
                    c = qg.iloc[0].get('cancelled_orders')
                    if pd.notna(c):
                        diff = (float(c) - canc_g_avg) / (canc_g_avg or 1.0) * 100.0 if canc_g_avg else 0.0
                        lines.append(f"  â€¢ ÐžÑ‚Ð¼ÐµÐ½Ñ‹ GRAB: {int(float(c))} Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {int(round(canc_g_avg))} ({diff:+.0f}%).")
                if not qj.empty and canc_j_avg is not None:
                    c = qj.iloc[0].get('cancelled_orders')
                    if pd.notna(c):
                        diff = (float(c) - canc_j_avg) / (canc_j_avg or 1.0) * 100.0 if canc_j_avg else 0.0
                        lines.append(f"  â€¢ ÐžÑ‚Ð¼ÐµÐ½Ñ‹ GOJEK: {int(float(c))} Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¼ÐµÐ´Ð¸Ð°Ð½Ñ‹ {int(round(canc_j_avg))} ({diff:+.0f}%).")
                # External context
                if temp is not None and sub['temp'].notna().any():
                    med_t = float(sub['temp'].median())
                    lines.append(f"  â€¢ Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°: {temp:.1f}Â°C (Ð¼ÐµÐ´Ð¸Ð°Ð½Ð° {med_t:.1f}Â°C).")
                if hum is not None and sub['humidity'].notna().any():
                    med_h = float(sub['humidity'].median())
                    lines.append(f"  â€¢ Ð’Ð»Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ: {hum:.0f}% (Ð¼ÐµÐ´Ð¸Ð°Ð½Ð° {med_h:.0f}%).")
                if wind is not None and sub['wind'].notna().any():
                    med_w = float(sub['wind'].median())
                    lines.append(f"  â€¢ Ð’ÐµÑ‚ÐµÑ€: {wind:.1f} (Ð¼ÐµÐ´Ð¸Ð°Ð½Ð° {med_w:.1f}).")
                # Holiday context (previous day)
                try:
                    prev_d = (pd.to_datetime(ds) - pd.Timedelta(days=1)).date()
                    prev_h = int(sub.loc[sub['date'].dt.date == prev_d, 'is_holiday'].fillna(0).max()) if not sub.empty else 0
                    if prev_h:
                        lines.append("  â€¢ ÐÐ°ÐºÐ°Ð½ÑƒÐ½Ðµ Ð±Ñ‹Ð» Ð¿Ñ€Ð°Ð·Ð´Ð½Ð¸Ðº â€” Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð´ÐµÐ½ÑŒ ÑÐ»Ð°Ð±ÐµÐµ.")
                except Exception:
                    pass
                lines.append("")
            except Exception:
                pass

            # What-if: Ð¿ÐµÑ€ÐµÐ½ÐµÑÐµÐ½Ð¾ Ð² Ñ€Ð°Ð·Ð´ÐµÐ» 9; Ð·Ð´ÐµÑÑŒ Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ñ‡Ð¸ÑÑ‚ÑƒÑŽ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÑƒ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½.
            lines.append("")

        # Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°: Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÑ„Ñ„ÐµÐºÑ‚Ð° Ð´Ð¾Ð¶Ð´Ñ Ð¸ Ð¿Ñ€Ð°Ð·Ð´Ð½Ð¸ÐºÐ¾Ð²
        lines.append("Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð¾Ð² Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´:")
        sub['heavy_rain'] = (sub['rain'].fillna(0.0) >= 10.0).astype(int)
        by_rain = sub.groupby('heavy_rain')['total_sales'].mean().to_dict()
        if 0 in by_rain:
            dr = (by_rain.get(1, by_rain[0]) - by_rain[0]) / (by_rain[0] or 1.0) * 100.0
            lines.append(f"  â€¢ ðŸŒ§ï¸ Ð”Ð¾Ð¶Ð´ÑŒ (Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° ÑÑ€ÐµÐ´Ð½Ð¸Ñ…): {_fmt_pct(dr)}")
        by_h = sub.groupby(sub['is_holiday'].fillna(0).astype(int))['total_sales'].mean().to_dict()
        if 0 in by_h:
            dh = (by_h.get(1, by_h[0]) - by_h[0]) / (by_h[0] or 1.0) * 100.0
            lines.append(f"  â€¢ ðŸŽŒ ÐŸÑ€Ð°Ð·Ð´Ð½Ð¸ÐºÐ¸ (Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° ÑÑ€ÐµÐ´Ð½Ð¸Ñ…): {_fmt_pct(dh)}")
        lines.append("")
        lines.append("Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸: SQLite (grab_stats, gojek_stats), Openâ€‘Meteo, Holidays cache")
        return "\n".join(lines)
    except Exception:
        return "8. ðŸš¨ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð”ÐÐ˜ (ML)\n" + ("â€”" * 72) + "\nÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð´ÐµÐ» (Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…)."


def _section9_recommendations(period: str, restaurant_id: int) -> str:
    try:
        # Use SHAP over the whole period to prioritize levers; exclude trivial features
        start_str, end_str = period.split("_")
        df = pd.read_csv("/workspace/data/merged_dataset.csv", parse_dates=["date"]) if os.path.exists("/workspace/data/merged_dataset.csv") else pd.DataFrame()
        sub = df[(df.get("restaurant_id") == restaurant_id) & (df.get("date") >= start_str) & (df.get("date") <= end_str)].copy() if not df.empty else pd.DataFrame()
        lines = []
        lines.append("9. ðŸŽ¯ Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜")
        lines.append("â€”" * 72)
        if sub.empty:
            lines.append("ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´.")
            return "\n".join(lines)

        # Load model and compute feature importances
        model, features, background = load_artifacts("/workspace/ml/artifacts")
        X = sub[features]
        pre = model.named_steps["pre"]
        mdl = model.named_steps["model"]
        X_pre = pre.transform(X)
        try:
            if background is not None and not background.empty:
                bg_pre = pre.transform(background[features])
                explainer = shap.TreeExplainer(mdl, data=bg_pre, feature_perturbation="interventional")
            else:
                explainer = shap.TreeExplainer(mdl, feature_perturbation="interventional")
            shap_values = explainer.shap_values(X_pre)
        except Exception:
            explainer = shap.TreeExplainer(mdl)
            shap_values = explainer.shap_values(X_pre)
        _, groups = _resolve_preprocessed_feature_groups(pre)
        import re as _re
        pat = [_re.compile(r"^orders_count(?!.*conversion).*"), _re.compile(r"^total_sales.*"), _re.compile(r"^restaurant_id$")]
        def is_excl(n: str) -> bool:
            return any(p.search(n) for p in pat)
        abs_sv = np.abs(shap_values)
        agg: Dict[str, float] = {}
        for feat, idxs in groups.items():
            if is_excl(feat) or not idxs:
                continue
            agg[feat] = float(abs_sv[:, idxs].mean())
        top = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:8]

        # Group by categories
        cats: Dict[str, float] = {}
        for f, v in agg.items():
            c = _categorize_feature(f)
            cats[c] = cats.get(c, 0.0) + v
        tot = sum(cats.values()) or 1.0
        for k in list(cats.keys()):
            cats[k] = round(100.0 * cats[k] / tot, 1)

        lines.append("ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ñ‹ Ð¿Ð¾ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð°Ð¼ (ML):")
        for f, v in top:
            lines.append(f"  â€¢ [{_categorize_feature(f)}] {_pretty_feature_name(f)}")
        lines.append("")
        lines.append("Ð’ÐºÐ»Ð°Ð´ Ð³Ñ€ÑƒÐ¿Ð¿ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð¾Ð²:")
        for k in ["Operations", "Marketing", "External", "Quality", "Other"]:
            if k in cats:
                lines.append(f"  â€¢ {k}: {cats[k]}%")
        lines.append("")
        lines.append("Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ:")
        if cats.get("Operations", 0) >= 30.0:
            lines.append("  â€¢ Ð¡Ð¾ÐºÑ€Ð°Ñ‚Ð¸Ñ‚ÑŒ SLA (prep/accept/delivery) Ð² Ð¿Ð¸ÐºÐ¾Ð²Ñ‹Ðµ Ð¾ÐºÐ½Ð°; Ð¿Ñ€ÐµÐ´Ð·Ð°Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸, ÑÐ»Ð¾Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð²Ñ‹Ð´Ð°Ñ‡Ð¸")
        if cats.get("Marketing", 0) >= 20.0:
            lines.append("  â€¢ ÐŸÐµÑ€ÐµÑ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ð±ÑŽÐ´Ð¶ÐµÑ‚ Ð² ÑÐ²ÑÐ·ÐºÐ¸ Ñ Ð»ÑƒÑ‡ÑˆÐ¸Ð¼ ROAS; Ñ‚ÐµÑÑ‚ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð¾Ð² Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¹; ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° ÑÑ‚Ð°Ð²Ð¾Ðº")
        lines.append("  â€¢ ÐŸÐ¾Ð³Ð¾Ð´Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð¼Ð¾ Ð¸ Ð±Ð¾Ð½ÑƒÑÑ‹ ÐºÑƒÑ€ÑŒÐµÑ€Ð°Ð¼ Ð² Ð´Ð¾Ð¶Ð´ÑŒ; Ð¿ÐµÑ€ÐµÐ½Ð¾Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð½Ð° Â«ÑÑƒÑ…Ð¸ÐµÂ» Ð¾ÐºÐ½Ð°")
        lines.append("  â€¢ Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð°Ð·Ð´Ð½Ð¸ÐºÐ¸ Ð² Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ (ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð°/Ð°ÐºÑ†Ð¸Ð¸ Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð´ÐµÐ½ÑŒ)")
        lines.append("  â€¢ ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¸ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¾Ð²: Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð¾Ð¼, ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ")
        return "\n".join(lines)
    except Exception:
        return "9. ðŸŽ¯ Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜\n" + ("â€”" * 72) + "\nÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸."


def generate_full_report(period: str, restaurant_id: int) -> str:
    basic = build_basic_report(period, restaurant_id)
    marketing = build_marketing_report(period, restaurant_id)
    quality = build_quality_report(period, restaurant_id)
    finance = basic.get("finance") if isinstance(basic, dict) else None

    parts = []
    # Dataset version banner
    banner = _dataset_version_banner()
    if banner:
        parts.append(banner)
        parts.append("")
    # Section 1
    parts.append(_section1_exec(basic))
    parts.append("")
    # Section 2
    parts.append(_section2_trends(basic))
    parts.append("")
    # Section 3
    parts.append(_section3_clients(period, restaurant_id))
    parts.append("")
    # Section 4
    parts.append(_section4_marketing(marketing))
    parts.append("")
    # Section 5
    if finance:
        parts.append(_section5_finance(finance))
        parts.append("")
    # Section 6
    parts.append(_section6_operations(period, restaurant_id))
    parts.append("")
    # Section 7
    parts.append(_section7_quality(quality))
    parts.append("")
    # Section 8 (ML Critical Days)
    parts.append(_section8_critical_days_ml(period, restaurant_id))
    parts.append("")
    # Section 9 (Recommendations)
    parts.append(_section9_recommendations(period, restaurant_id))
    parts.append("")
    return "\n".join(parts)