#!/usr/bin/env python3
"""
–°–Ω–∞–ø—à–æ—Ç-—Ç–µ—Å—Ç—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ 8 "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–Ω–∏"
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –±–ª–æ–∫–æ–≤ –∏ —á–∏—Å–ª–æ–≤—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç—á–µ—Ç–æ–≤
"""

import re
import os
import sys
from typing import Dict, List, Tuple, Optional

def extract_key_metrics(report_text: str) -> Dict[str, any]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    metrics = {}
    
    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–∑–¥–µ–ª–∞ 8
    section8_match = re.search(r'8\. üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –î–ù–ò.*?(?=9\.|$)', report_text, re.DOTALL)
    if not section8_match:
        return {"error": "–†–∞–∑–¥–µ–ª 8 –Ω–µ –Ω–∞–π–¥–µ–Ω"}
    
    section8_text = section8_match.group(0)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π
    critical_days_match = re.search(r'–ù–∞–π–¥–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π.*?(\d+) –∏–∑ (\d+)', section8_text)
    if critical_days_match:
        metrics["critical_days_found"] = int(critical_days_match.group(1))
        metrics["total_days"] = int(critical_days_match.group(2))
        metrics["critical_days_percentage"] = metrics["critical_days_found"] / metrics["total_days"] * 100
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ–¥–∏–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏
    median_match = re.search(r'–ú–µ–¥–∏–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏: ([\d\s]+(?:\.\d+)?)\s*(?:M\s*)?IDR', section8_text)
    if median_match:
        median_str = median_match.group(1).replace(' ', '').replace('M', '000000')
        try:
            metrics["median_sales"] = float(median_str)
        except:
            metrics["median_sales"] = None
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—â–∏–µ –ø–æ—Ç–µ—Ä–∏
    losses_match = re.search(r'–û–±—â–∏–µ –ø–æ—Ç–µ—Ä–∏.*?([\d\s]+(?:\.\d+)?)\s*(?:M\s*)?IDR', section8_text)
    if losses_match:
        losses_str = losses_match.group(1).replace(' ', '').replace('M', '000000')
        try:
            metrics["total_losses"] = float(losses_str)
        except:
            metrics["total_losses"] = None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤
    required_blocks = [
        "–ö–õ–Æ–ß–ï–í–´–ï –¶–ò–§–†–´",
        "–†–ï–ê–õ–¨–ù–´–ï –ü–†–ò–ß–ò–ù–´", 
        "–í–ù–ï–®–ù–ò–ï –§–ê–ö–¢–û–†–´",
        "–ö–û–ù–ö–†–ï–¢–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò",
        "–§–ò–ù–ê–ù–°–û–í–´–ô –ò–¢–û–ì"
    ]
    
    metrics["blocks_found"] = []
    for block in required_blocks:
        if block in section8_text:
            metrics["blocks_found"].append(block)
    
    metrics["blocks_coverage"] = len(metrics["blocks_found"]) / len(required_blocks) * 100
    
    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
    detailed_days = len(re.findall(r'üî¥ \d{4}-\d{2}-\d{2}', section8_text))
    metrics["detailed_days_analyzed"] = detailed_days
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    roi_recommendations = len(re.findall(r'–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç.*?IDR', section8_text))
    metrics["roi_recommendations"] = roi_recommendations
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ "–ø–æ–ª–æ—Ç–Ω–∞" - –¥–ª–∏–Ω–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤ –±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    long_paragraphs = len(re.findall(r'[^\n]{200,}', section8_text))
    metrics["long_paragraphs"] = long_paragraphs
    
    return metrics


def test_restaurant_period(restaurant_id: int, period: str, restaurant_name: str) -> Dict[str, any]:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ä–µ—Å—Ç–æ—Ä–∞–Ω –∑–∞ –æ–¥–∏–Ω –ø–µ—Ä–∏–æ–¥"""
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É—é {restaurant_name} –∑–∞ {period}...")
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞
        sys.path.append('/workspace')
        from app.report_text import generate_full_report
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = generate_full_report(period, restaurant_id)
        
        if not report or len(report) < 1000:
            return {"error": f"–û—Ç—á–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {len(report)} —Å–∏–º–≤–æ–ª–æ–≤"}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = extract_key_metrics(report)
        metrics["restaurant_name"] = restaurant_name
        metrics["period"] = period
        metrics["report_length"] = len(report)
        
        return metrics
        
    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}"}


def validate_metrics(metrics: Dict[str, any], test_name: str) -> Tuple[bool, List[str]]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º"""
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –†–∞–∑–¥–µ–ª 8 –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
    if "error" in metrics:
        issues.append(f"‚ùå {metrics['error']}")
        return False, issues
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–Ω–∏ (–∏–ª–∏ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–æ)
    if "critical_days_found" not in metrics:
        issues.append("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π")
    elif metrics["critical_days_found"] > 10:
        issues.append(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π: {metrics['critical_days_found']} (–≤–æ–∑–º–æ–∂–Ω–æ —Å–ª–∏—à–∫–æ–º –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ü—Ä–æ—Ü–µ–Ω—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑—É–º–Ω—ã–º
    if "critical_days_percentage" in metrics:
        if metrics["critical_days_percentage"] > 50:
            issues.append(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π: {metrics['critical_days_percentage']:.1f}%")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 4: –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
    if "blocks_coverage" in metrics:
        if metrics["blocks_coverage"] < 80:
            missing_blocks = 5 - len(metrics.get("blocks_found", []))
            issues.append(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞–µ—Ç –±–ª–æ–∫–æ–≤: {missing_blocks}, –ø–æ–∫—Ä—ã—Ç–∏–µ {metrics['blocks_coverage']:.1f}%")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 5: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–ª—è –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–Ω–µ–π
    if "critical_days_found" in metrics and "detailed_days_analyzed" in metrics:
        if metrics["detailed_days_analyzed"] < metrics["critical_days_found"]:
            issues.append(f"‚ùå –ù–µ –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–Ω–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã: {metrics['detailed_days_analyzed']}/{metrics['critical_days_found']}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 6: –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å ROI
    if "roi_recommendations" in metrics:
        if metrics["roi_recommendations"] == 0:
            issues.append("‚ùå –ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º —ç—Ñ—Ñ–µ–∫—Ç–æ–º")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 7: –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å "–ø–æ–ª–æ—Ç–Ω–∞" —Ç–µ–∫—Å—Ç–∞
    if "long_paragraphs" in metrics:
        if metrics["long_paragraphs"] > 2:
            issues.append(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {metrics['long_paragraphs']} –¥–ª–∏–Ω–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤ (–≤–æ–∑–º–æ–∂–Ω–æ '–ø–æ–ª–æ—Ç–Ω–æ')")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 8: –†–∞–∑–º–µ—Ä –æ—Ç—á–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑—É–º–Ω—ã–º
    if "report_length" in metrics:
        if metrics["report_length"] > 50000:
            issues.append(f"‚ö†Ô∏è –û—Ç—á–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {metrics['report_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        elif metrics["report_length"] < 3000:
            issues.append(f"‚ö†Ô∏è –û—Ç—á–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {metrics['report_length']} —Å–∏–º–≤–æ–ª–æ–≤")
    
    success = len(issues) == 0
    return success, issues


def run_snapshot_tests():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–Ω–∞–ø—à–æ—Ç-—Ç–µ—Å—Ç—ã –Ω–∞ 2 —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ √ó 2 –ø–µ—Ä–∏–æ–¥–∞"""
    print("üöÄ –°–ù–ê–ü–®–û–¢-–¢–ï–°–¢–´ –†–ê–ó–î–ï–õ–ê 8")
    print("=" * 60)
    print()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏: 2 —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ √ó 2 –ø–µ—Ä–∏–æ–¥–∞
    test_cases = [
        (11, "2025-04-01_2025-06-30", "Ika Canggu"),  # Q2 2025
        (11, "2025-05-01_2025-05-31", "Ika Canggu"),  # –ú–∞–π 2025
        (20, "2025-05-01_2025-05-31", "Only Eggs"),   # –ú–∞–π 2025
        (20, "2025-04-01_2025-04-30", "Only Eggs"),   # –ê–ø—Ä–µ–ª—å 2025
    ]
    
    results = []
    total_tests = len(test_cases)
    passed_tests = 0
    
    for restaurant_id, period, restaurant_name in test_cases:
        print(f"üìä –¢–µ—Å—Ç–∏—Ä—É—é: {restaurant_name} –∑–∞ {period}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = test_restaurant_period(restaurant_id, period, restaurant_name)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        test_name = f"{restaurant_name}_{period}"
        success, issues = validate_metrics(metrics, test_name)
        
        results.append({
            "test_name": test_name,
            "success": success,
            "metrics": metrics,
            "issues": issues
        })
        
        if success:
            print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            passed_tests += 1
        else:
            print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù")
            for issue in issues:
                print(f"   {issue}")
        
        print()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print("=" * 40)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {passed_tests}/{total_tests}")
    print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {passed_tests/total_tests*100:.1f}%")
    print()
    
    if passed_tests == total_tests:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
        print("‚úÖ –†–∞–∑–¥–µ–ª 8 —Å—Ç–∞–±–∏–ª–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ production")
        print("‚úÖ –ù–µ—Ç '–ø–æ–ª–æ—Ç–Ω–∞' —Ç–µ–∫—Å—Ç–∞")
        print("‚úÖ –í—Å–µ –±–ª–æ–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        print("‚úÖ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã")
    elif passed_tests >= total_tests * 0.75:
        print("‚ö†Ô∏è –ë–û–õ–¨–®–ò–ù–°–¢–í–û –¢–ï–°–¢–û–í –ü–†–û–ô–î–ï–ù–û")
        print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–±–æ–ª—å—à–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞")
    else:
        print("‚ùå –ú–ù–û–ì–û –ü–†–û–í–ê–õ–ï–ù–ù–´–• –¢–ï–°–¢–û–í")
        print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–µ—Ä—å–µ–∑–Ω–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–¥–µ–ª–∞ 8")
    
    return results


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤
    required_files = [
        "/workspace/data/merged_dataset.csv",
        "/workspace/ml/artifacts/model.joblib",
        "/workspace/ml/artifacts/features.json"
    ]
    
    missing_files = [f for f in required_files if not os.path.exists(f)]
    
    if missing_files:
        print("‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–¢ –ù–ï–û–ë–•–û–î–ò–ú–´–ï –§–ê–ô–õ–´:")
        for f in missing_files:
            print(f"   {f}")
        print()
        print("üîß –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞:")
        print("   python etl/data_loader.py --run")
        print("   python ml/training.py")
        sys.exit(1)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    results = run_snapshot_tests()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    import json
    with open('/workspace/section8_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ section8_test_results.json")