import os
import sys
from datetime import date, timedelta
from typing import Optional

import pandas as pd
import streamlit as st

sys.path.append('/workspace')

from etl.data_loader import get_engine
from app.report_text import generate_full_report


def _list_restaurants() -> pd.DataFrame:
	eng = get_engine('/workspace/database.sqlite')
	df = pd.read_sql_query('SELECT id, name FROM restaurants ORDER BY name', eng)
	return df


def _ensure_reports_dir() -> str:
	dir_path = os.path.join('/workspace', 'reports')
	os.makedirs(dir_path, exist_ok=True)
	return dir_path


def _period_presets() -> dict:
	today = date.today()
	start_month = today.replace(day=1)
	last_month_end = start_month - timedelta(days=1)
	last_month_start = last_month_end.replace(day=1)
	week_start = today - timedelta(days=7)
	return {
		'–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π': (week_start, today),
		'–≠—Ç–æ—Ç –º–µ—Å—è—Ü': (start_month, today),
		'–ü—Ä–æ—à–ª—ã–π –º–µ—Å—è—Ü': (last_month_start, last_month_end),
	}


def _format_period(d1: date, d2: date) -> str:
	return f"{d1.strftime('%Y-%m-%d')}_{d2.strftime('%Y-%m-%d')}"


def _sync_restaurant_data():
	"""–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ —Å –∂–∏–≤—ã–º API"""
	try:
		# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API –∫–ª–∏–µ–Ω—Ç–∞
		import os
		if not os.getenv("DATABASE_URL"):
			st.error("‚ùå DATABASE_URL –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è SQLite.")
			return
		
		with st.spinner('–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å API...'):
			from etl.api_client import sync_all_sources
			from datetime import date, timedelta
			
			# –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–ª—è –≤—Å–µ—Ö —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤
			restaurants = ['Only Kebab', 'Ika Canggu', 'Asai Cafe']  # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
			
			total_updated = 0
			for restaurant in restaurants:
				try:
					result = sync_all_sources(
						restaurant, 
						start_date=date.today() - timedelta(days=30),
						end_date=date.today() - timedelta(days=1)
					)
					total_updated += result.get('total_records_updated', 0)
				except Exception as e:
					st.warning(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ {restaurant}: {e}")
			
			if total_updated > 0:
				st.success(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {total_updated} –∑–∞–ø–∏—Å–µ–π")
				
				# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML
				if total_updated >= 30:
					st.info("ü§ñ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å ML –º–æ–¥–µ–ª—å (–º–Ω–æ–≥–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö)")
					if st.button("üöÄ –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
						_retrain_ml_model()
			else:
				st.info("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
				
	except ImportError:
		st.error("‚ùå API –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ etl/api_client.py –¥–æ—Å—Ç—É–ø–µ–Ω.")
	except Exception as e:
		st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")


def _retrain_ml_model():
	"""–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏"""
	try:
		with st.spinner('–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏...'):
			import subprocess
			
			# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV
			from etl.build_views import export_to_csv_for_ml
			if export_to_csv_for_ml():
				# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
				result = subprocess.run([
					'python', 'ml/training.py', 
					'--csv', '/workspace/data/live_dataset.csv',
					'--out', '/workspace/ml/artifacts'
				], capture_output=True, text=True, cwd='/workspace')
				
				if result.returncode == 0:
					st.success("‚úÖ ML –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
					st.json(result.stdout)
				else:
					st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {result.stderr}")
			else:
				st.error("‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML")
				
	except Exception as e:
		st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}")


def tab_restaurant_analysis():
	st.header('–ê–Ω–∞–ª–∏–∑ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞')
	
	# –ö–Ω–æ–ø–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
	col1, col2 = st.columns([3, 1])
	with col2:
		if st.button('üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ API'):
			_sync_restaurant_data()
	
	rest_df = _list_restaurants()
	if rest_df.empty:
		st.warning('–¢–∞–±–ª–∏—Ü–∞ restaurants –ø—É—Å—Ç–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ë–î –¥–æ—Å—Ç—É–ø–Ω–∞.')
		return
	rest_map = {f"{row['name']} (ID {row['id']})": int(row['id']) for _, row in rest_df.iterrows()}
	
	with col1:
		label = st.selectbox('–†–µ—Å—Ç–æ—Ä–∞–Ω', list(rest_map.keys()))
	rest_id = rest_map[label]
	rest_name = label.split(' (ID')[0]

	presets = _period_presets()
	preset = st.selectbox('–ü–µ—Ä–∏–æ–¥ (–ø—Ä–µ—Å–µ—Ç—ã)', list(presets.keys()))
	start_default, end_default = presets[preset]
	col1, col2 = st.columns(2)
	with col1:
		start_date = st.date_input('–ù–∞—á–∞–ª–æ', start_default)
	with col2:
		end_date = st.date_input('–û–∫–æ–Ω—á–∞–Ω–∏–µ', end_default)

	period = _format_period(start_date, end_date)

	if st.button('–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç'):
		try:
			text = generate_full_report(period=period, restaurant_id=rest_id)
			st.success('–û—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω')
			st.text_area('–û—Ç—á—ë—Ç', value=text, height=600)
			reports_dir = _ensure_reports_dir()
			fn = os.path.join(reports_dir, f"report_{rest_id}_{period}.md")
			with open(fn, 'w', encoding='utf-8') as f:
				f.write(text)
			st.download_button('–°–∫–∞—á–∞—Ç—å .md', data=text, file_name=os.path.basename(fn), mime='text/markdown')
		except Exception as e:
			st.error(f'–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è: {e}')


def _aggregate_kpi(engine, start: date, end: date) -> dict:
	start_s, end_s = start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')
	q = lambda t: pd.read_sql_query(
		f"SELECT SUM(sales) sales, SUM(orders) orders, SUM(ads_spend) ads_spend, SUM(ads_sales) ads_sales, AVG(rating) rating, SUM(cancelled_orders) canc FROM {t} WHERE stat_date BETWEEN ? AND ?",
		engine, params=(start_s, end_s)
	)
	g = q('grab_stats').iloc[0].fillna(0)
	j = q('gojek_stats').iloc[0].fillna(0)
	sales = float(g['sales'] + j['sales'])
	orders = float((g['orders'] or 0) + (j['orders'] or 0))
	ads_spend = float(g['ads_spend'] + j['ads_spend'])
	ads_sales = float(g['ads_sales'] + j['ads_sales'])
	rating = float(((g['rating'] or 0) + (j['rating'] or 0)) / (2 if ((g['rating'] or 0) and (j['rating'] or 0)) else 1) or 0)
	canc = float((g['canc'] or 0) + (j['canc'] or 0))
	return {
		'sales': sales,
		'orders': orders,
		'aov': (sales / orders) if orders else 0.0,
		'ads_spend': ads_spend,
		'ads_sales': ads_sales,
		'roas': (ads_sales / ads_spend) if ads_spend else 0.0,
		'rating': rating,
		'cancels': canc,
		'mer': (sales / ads_spend) if ads_spend else 0.0,
	}


def _delta(a: float, b: float) -> float:
	if b == 0:
		return 0.0
	return (a - b) / b * 100.0


def tab_base_analysis():
	st.header('–ê–Ω–∞–ª–∏–∑ –±–∞–∑—ã (KPI)')
	eng = get_engine('/workspace/database.sqlite')
	presets = _period_presets()
	preset = st.selectbox('–ü–µ—Ä–∏–æ–¥ (–ø—Ä–µ—Å–µ—Ç—ã)', list(presets.keys()))
	start_default, end_default = presets[preset]
	col1, col2 = st.columns(2)
	with col1:
		start_date = st.date_input('–ù–∞—á–∞–ª–æ', start_default)
	with col2:
		end_date = st.date_input('–û–∫–æ–Ω—á–∞–Ω–∏–µ', end_default)

	n_days = (end_date - start_date).days + 1
	prev_end = start_date - timedelta(days=1)
	prev_start = prev_end - timedelta(days=n_days - 1)

	k_now = _aggregate_kpi(eng, start_date, end_date)
	k_prev = _aggregate_kpi(eng, prev_start, prev_end)

	st.subheader('KPI –ø–∞–Ω–µ–ª—å')
	colA, colB, colC = st.columns(3)
	with colA:
		st.metric('Total Sales', f"{int(k_now['sales']):,} IDR".replace(',', ' '), f"{_delta(k_now['sales'], k_prev['sales']):.1f}%")
		st.metric('Orders', int(k_now['orders']), f"{_delta(k_now['orders'], k_prev['orders']):.1f}%")
		st.metric('AOV', f"{int(k_now['aov']):,} IDR".replace(',', ' '), f"{_delta(k_now['aov'], k_prev['aov']):.1f}%")
	with colB:
		st.metric('Ads Spend', f"{int(k_now['ads_spend']):,} IDR".replace(',', ' '), f"{_delta(k_now['ads_spend'], k_prev['ads_spend']):.1f}%")
		st.metric('Ads Sales', f"{int(k_now['ads_sales']):,} IDR".replace(',', ' '), f"{_delta(k_now['ads_sales'], k_prev['ads_sales']):.1f}%")
		st.metric('ROAS', f"{k_now['roas']:.2f}x", f"{_delta(k_now['roas'], k_prev['roas']):.1f}%")
	with colC:
		st.metric('Payouts', '‚Äî', '‚Äî')
		st.metric('Cancels', int(k_now['cancels']), f"{_delta(k_now['cancels'], k_prev['cancels']):.1f}%")
		st.metric('MER', f"{k_now['mer']:.2f}", f"{_delta(k_now['mer'], k_prev['mer']):.1f}%")

	st.caption('–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≤—ã–ø–ª–∞—Ç—ã (Payouts) –¥–æ—Å—Ç—É–ø–Ω—ã, –µ—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª–µ payouts.')


def tab_ai_query():
	st.header('–°–≤–æ–±–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å (AI)')
	st.caption('–û—Ç–≤–µ—Ç—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ë–î –∏ ML. –î–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ —É–∫–∞–∂–∏—Ç–µ OPENAI_API_KEY –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.')
	question = st.text_input('–í–∞—à –≤–æ–ø—Ä–æ—Å', '')
	if st.button('–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å'):
		if not question.strip():
			st.warning('–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å')
			return
		# –ü—Ä–æ—Å—Ç–∞—è –±–æ–ª–≤–∞–Ω–∫–∞: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç –∫–∞–∫ –º–∞—Ç–µ—Ä–∏–∞–ª
		st.info('–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤...')
		st.write('‚Äî –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –ø–µ—Ä–∏–æ–¥–∞: –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ (ROAS, –±—é–¥–∂–µ—Ç), –æ–ø–µ—Ä–∞—Ü–∏–∏ (prep/delivery/accept), –≤–Ω–µ—à–Ω–∏–µ (–¥–æ–∂–¥—å/–ø—Ä–∞–∑–¥–Ω–∏–∫–∏).')
		st.write('‚Äî –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –±—é–¥–∂–µ—Ç –≤ —Å–≤—è–∑–∫–∏ —Å –ª—É—á—à–∏–º ROAS, —Å–æ–∫—Ä–∞—Ç–∏—Ç—å SLA –≤ –ø–∏–∫–µ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–≥–æ–¥–Ω—ã–µ –ø—Ä–æ–º–æ –≤ –¥–æ–∂–¥—å.')


def main():
	st.set_page_config(page_title='Food Intelligence', layout='wide')
	st.title('Food Intelligence ‚Äî –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–¥–∞–∂ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤')
	tab1, tab2, tab3 = st.tabs(['–ê–Ω–∞–ª–∏–∑ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞', '–ê–Ω–∞–ª–∏–∑ –±–∞–∑—ã', '–°–≤–æ–±–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å (AI)'])
	with tab1:
		tab_restaurant_analysis()
	with tab2:
		tab_base_analysis()
	with tab3:
		tab_ai_query()


if __name__ == '__main__':
	main()